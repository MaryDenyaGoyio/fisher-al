{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f79bae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Libraries'''\n",
    "import numpy as np, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "from laplace import Laplace\n",
    "import matplotlib.pyplot as plt\n",
    "import laplace\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bb46c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.TensorDataset object at 0x000001C802668B50>\n"
     ]
    }
   ],
   "source": [
    "'''Dataset Loader for Digits dataset'''\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Data\n",
    "digits = load_digits()\n",
    "X, y = digits.data.astype(np.float32), digits.target.astype(np.int64)\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)\n",
    "\n",
    "scaler = StandardScaler().fit(Xtr)\n",
    "Xtr, Xte = scaler.transform(Xtr), scaler.transform(Xte)\n",
    "\n",
    "Xtr_t = torch.from_numpy(Xtr)\n",
    "ytr_t = torch.from_numpy(ytr)\n",
    "Xte_t = torch.from_numpy(Xte)\n",
    "yte_t = torch.from_numpy(yte)\n",
    "\n",
    "train_set = TensorDataset(Xtr_t, ytr_t)\n",
    "print(train_set)\n",
    "n_train = len(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60222c69",
   "metadata": {},
   "source": [
    "Task 1.1\n",
    "According To Parameter of Model increasing, Does it's spectrum changes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a51551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model, only_trainable=False):\n",
    "    \"\"\"\n",
    "    Î™®Îç∏Ïùò ÌååÎùºÎØ∏ÌÑ∞ Í∞úÏàòÎ•º Î∞òÌôòÌï©ÎãàÎã§.\n",
    "    only_trainable=TrueÏù¥Î©¥ requires_grad=TrueÏù∏ ÌååÎùºÎØ∏ÌÑ∞Îßå ÏÖâÎãàÎã§.\n",
    "    \"\"\"\n",
    "    params = (p for p in model.parameters() if (not only_trainable) or p.requires_grad)\n",
    "    return sum(p.numel() for p in params)\n",
    "\n",
    "def get_models():\n",
    "    models = []\n",
    "\n",
    "    # 1. Í∞ÄÏû• Îã®ÏàúÌïú Î™®Îç∏\n",
    "    models.append(nn.Linear(64, 10))\n",
    "\n",
    "    # 2. ÌååÎùºÎØ∏ÌÑ∞ 2Î∞∞: Linear + Linear\n",
    "    models.append(nn.Sequential(\n",
    "        nn.Linear(64, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 10)\n",
    "    ))\n",
    "\n",
    "    # 3. Îçî ÍπäÍ≤å: Linear + Linear + Linear\n",
    "    models.append(nn.Sequential(\n",
    "        nn.Linear(64, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 10)\n",
    "    ))\n",
    "\n",
    "    # 4. Îçî ÍπäÍ≥† ÎÑìÍ≤å\n",
    "    models.append(nn.Sequential(\n",
    "        nn.Linear(64, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 10)\n",
    "    ))\n",
    "\n",
    "    # 5. BatchNorm Ï∂îÍ∞Ä\n",
    "    models.append(nn.Sequential(\n",
    "        nn.Linear(64, 128),\n",
    "        nn.BatchNorm1d(128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 10)\n",
    "    ))\n",
    "\n",
    "    # 6. Dropout Ï∂îÍ∞Ä\n",
    "    models.append(nn.Sequential(\n",
    "        nn.Linear(64, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 10)\n",
    "    ))\n",
    "\n",
    "    # 7. Îçî ÍπäÍ≤å, Îçî ÎÑìÍ≤å\n",
    "    models.append(nn.Sequential(\n",
    "        nn.Linear(64, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 10)\n",
    "    ))\n",
    "\n",
    "    # 8. Îçî ÎßéÏùÄ Î†àÏù¥Ïñ¥ÏôÄ BatchNorm, Dropout\n",
    "    models.append(nn.Sequential(\n",
    "        nn.Linear(64, 512),\n",
    "        nn.BatchNorm1d(512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 10)\n",
    "    ))\n",
    "\n",
    "    # 9. Îçî ÍπäÍ≥† ÎÑìÍ≤å, ÌôúÏÑ±Ìôî Îã§ÏñëÌôî\n",
    "    models.append(nn.Sequential(\n",
    "        nn.Linear(64, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, 512),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(512, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 10)\n",
    "    ))\n",
    "\n",
    "    # 10. Í∞ÄÏû• ÌÅ∞ Î™®Îç∏\n",
    "    models.append(nn.Sequential(\n",
    "        nn.Linear(64, 1024),\n",
    "        nn.BatchNorm1d(1024),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.4),\n",
    "        nn.Linear(1024, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 10)\n",
    "    ))\n",
    "\n",
    "    return models\n",
    "\n",
    "def evaluate(loader, model):\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in loader:\n",
    "                outputs = model(inputs)\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        return correct / total\n",
    "\n",
    "def cumulative_explained_ratio(val, alpha=0.9):\n",
    "    \"\"\"\n",
    "    val: list or np.array of eigenvalues (can be positive/negative)\n",
    "    alpha: target cumulative proportion (e.g., 0.9)\n",
    "    \n",
    "    Returns:\n",
    "        ratio (float): index/p where cumulative sum first exceeds alpha\n",
    "        idx (int): the actual index achieving it\n",
    "    \"\"\"\n",
    "    val = np.array(val, dtype=float)\n",
    "    # ÏùåÏàò Í∞íÏùÄ curvature ÏÑ§Î™ÖÏóê Í∏∞Ïó¨ÌïòÏßÄ ÏïäÎèÑÎ°ù Ï†úÍ±∞ (ÌïÑÏöîÏãú ÏòµÏÖòÌôî Í∞ÄÎä•)\n",
    "    val = np.maximum(val, 0)\n",
    "    \n",
    "    if np.sum(val) == 0:\n",
    "        return 0.0, 0\n",
    "\n",
    "    sorted_vals = np.sort(val)[::-1]  # ÎÇ¥Î¶ºÏ∞®Ïàú Ï†ïÎ†¨\n",
    "    cumvals = np.cumsum(sorted_vals)\n",
    "    total = cumvals[-1]\n",
    "    threshold = alpha * total\n",
    "\n",
    "    idx = np.searchsorted(cumvals, threshold)\n",
    "    ratio = (idx + 1) / len(val)\n",
    "    return ratio, idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b61c76b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 650 parameters\n",
      "Epoch 1/30 - loss: 1.1704 - train_acc: 0.9161 - test_acc: 0.9022\n",
      "Epoch 2/30 - loss: 0.3727 - train_acc: 0.9480 - test_acc: 0.9267\n",
      "Epoch 3/30 - loss: 0.2682 - train_acc: 0.9547 - test_acc: 0.9333\n",
      "Epoch 4/30 - loss: 0.2228 - train_acc: 0.9614 - test_acc: 0.9400\n",
      "Epoch 5/30 - loss: 0.1957 - train_acc: 0.9673 - test_acc: 0.9467\n",
      "Epoch 6/30 - loss: 0.1773 - train_acc: 0.9681 - test_acc: 0.9467\n",
      "Epoch 7/30 - loss: 0.1793 - train_acc: 0.9718 - test_acc: 0.9511\n",
      "Epoch 8/30 - loss: 0.1478 - train_acc: 0.9740 - test_acc: 0.9578\n",
      "Epoch 9/30 - loss: 0.1404 - train_acc: 0.9770 - test_acc: 0.9600\n",
      "Epoch 10/30 - loss: 0.1294 - train_acc: 0.9777 - test_acc: 0.9622\n",
      "Epoch 11/30 - loss: 0.1222 - train_acc: 0.9777 - test_acc: 0.9622\n",
      "Epoch 12/30 - loss: 0.1168 - train_acc: 0.9785 - test_acc: 0.9622\n",
      "Epoch 13/30 - loss: 0.1112 - train_acc: 0.9807 - test_acc: 0.9622\n",
      "Epoch 14/30 - loss: 0.1065 - train_acc: 0.9800 - test_acc: 0.9622\n",
      "Epoch 15/30 - loss: 0.1024 - train_acc: 0.9822 - test_acc: 0.9622\n",
      "Epoch 16/30 - loss: 0.0990 - train_acc: 0.9822 - test_acc: 0.9622\n",
      "Epoch 17/30 - loss: 0.0954 - train_acc: 0.9807 - test_acc: 0.9622\n",
      "Epoch 18/30 - loss: 0.0937 - train_acc: 0.9859 - test_acc: 0.9622\n",
      "Epoch 19/30 - loss: 0.0923 - train_acc: 0.9844 - test_acc: 0.9622\n",
      "Epoch 20/30 - loss: 0.0870 - train_acc: 0.9866 - test_acc: 0.9622\n",
      "Epoch 21/30 - loss: 0.0905 - train_acc: 0.9889 - test_acc: 0.9622\n",
      "Epoch 22/30 - loss: 0.0846 - train_acc: 0.9881 - test_acc: 0.9644\n",
      "Epoch 23/30 - loss: 0.0801 - train_acc: 0.9889 - test_acc: 0.9644\n",
      "Epoch 24/30 - loss: 0.0786 - train_acc: 0.9881 - test_acc: 0.9622\n",
      "Epoch 25/30 - loss: 0.0755 - train_acc: 0.9874 - test_acc: 0.9644\n",
      "Epoch 26/30 - loss: 0.0747 - train_acc: 0.9903 - test_acc: 0.9622\n",
      "Epoch 27/30 - loss: 0.0811 - train_acc: 0.9903 - test_acc: 0.9622\n",
      "Epoch 28/30 - loss: 0.0726 - train_acc: 0.9911 - test_acc: 0.9600\n",
      "Epoch 29/30 - loss: 0.0701 - train_acc: 0.9926 - test_acc: 0.9622\n",
      "Epoch 30/30 - loss: 0.0674 - train_acc: 0.9903 - test_acc: 0.9622\n",
      "Training model with 4810 parameters\n",
      "Epoch 1/30 - loss: 1.8087 - train_acc: 0.8189 - test_acc: 0.7889\n",
      "Epoch 2/30 - loss: 0.6958 - train_acc: 0.9176 - test_acc: 0.9067\n",
      "Epoch 3/30 - loss: 0.3222 - train_acc: 0.9473 - test_acc: 0.9378\n",
      "Epoch 4/30 - loss: 0.2131 - train_acc: 0.9584 - test_acc: 0.9444\n",
      "Epoch 5/30 - loss: 0.1630 - train_acc: 0.9696 - test_acc: 0.9511\n",
      "Epoch 6/30 - loss: 0.1306 - train_acc: 0.9777 - test_acc: 0.9578\n",
      "Epoch 7/30 - loss: 0.1091 - train_acc: 0.9800 - test_acc: 0.9644\n",
      "Epoch 8/30 - loss: 0.0894 - train_acc: 0.9859 - test_acc: 0.9733\n",
      "Epoch 9/30 - loss: 0.0779 - train_acc: 0.9889 - test_acc: 0.9733\n",
      "Epoch 10/30 - loss: 0.0684 - train_acc: 0.9948 - test_acc: 0.9756\n",
      "Epoch 11/30 - loss: 0.0632 - train_acc: 0.9941 - test_acc: 0.9756\n",
      "Epoch 12/30 - loss: 0.0618 - train_acc: 0.9963 - test_acc: 0.9756\n",
      "Epoch 13/30 - loss: 0.0486 - train_acc: 0.9970 - test_acc: 0.9756\n",
      "Epoch 14/30 - loss: 0.0441 - train_acc: 0.9978 - test_acc: 0.9756\n",
      "Epoch 15/30 - loss: 0.0399 - train_acc: 0.9985 - test_acc: 0.9756\n",
      "Epoch 16/30 - loss: 0.0360 - train_acc: 0.9985 - test_acc: 0.9756\n",
      "Epoch 17/30 - loss: 0.0332 - train_acc: 0.9985 - test_acc: 0.9756\n",
      "Epoch 18/30 - loss: 0.0307 - train_acc: 0.9993 - test_acc: 0.9756\n",
      "Epoch 19/30 - loss: 0.0283 - train_acc: 0.9985 - test_acc: 0.9756\n",
      "Epoch 20/30 - loss: 0.0267 - train_acc: 0.9993 - test_acc: 0.9756\n",
      "Epoch 21/30 - loss: 0.0247 - train_acc: 0.9993 - test_acc: 0.9756\n",
      "Epoch 22/30 - loss: 0.0231 - train_acc: 0.9993 - test_acc: 0.9778\n",
      "Epoch 23/30 - loss: 0.0220 - train_acc: 0.9993 - test_acc: 0.9778\n",
      "Epoch 24/30 - loss: 0.0204 - train_acc: 1.0000 - test_acc: 0.9778\n",
      "Epoch 25/30 - loss: 0.0194 - train_acc: 1.0000 - test_acc: 0.9778\n",
      "Epoch 26/30 - loss: 0.0183 - train_acc: 1.0000 - test_acc: 0.9778\n",
      "Epoch 27/30 - loss: 0.0175 - train_acc: 1.0000 - test_acc: 0.9778\n",
      "Epoch 28/30 - loss: 0.0168 - train_acc: 1.0000 - test_acc: 0.9778\n",
      "Epoch 29/30 - loss: 0.0160 - train_acc: 1.0000 - test_acc: 0.9778\n",
      "Epoch 30/30 - loss: 0.0150 - train_acc: 1.0000 - test_acc: 0.9800\n",
      "Training model with 17226 parameters\n",
      "Epoch 1/30 - loss: 2.2026 - train_acc: 0.7691 - test_acc: 0.7289\n",
      "Epoch 2/30 - loss: 1.4211 - train_acc: 0.8322 - test_acc: 0.7956\n",
      "Epoch 3/30 - loss: 0.5279 - train_acc: 0.9369 - test_acc: 0.9222\n",
      "Epoch 4/30 - loss: 0.2411 - train_acc: 0.9651 - test_acc: 0.9444\n",
      "Epoch 5/30 - loss: 0.1505 - train_acc: 0.9770 - test_acc: 0.9578\n",
      "Epoch 6/30 - loss: 0.1019 - train_acc: 0.9866 - test_acc: 0.9667\n",
      "Epoch 7/30 - loss: 0.0784 - train_acc: 0.9889 - test_acc: 0.9644\n",
      "Epoch 8/30 - loss: 0.0598 - train_acc: 0.9948 - test_acc: 0.9778\n",
      "Epoch 9/30 - loss: 0.0531 - train_acc: 0.9970 - test_acc: 0.9778\n",
      "Epoch 10/30 - loss: 0.0439 - train_acc: 0.9978 - test_acc: 0.9644\n",
      "Epoch 11/30 - loss: 0.0331 - train_acc: 0.9993 - test_acc: 0.9756\n",
      "Epoch 12/30 - loss: 0.0260 - train_acc: 1.0000 - test_acc: 0.9733\n",
      "Epoch 13/30 - loss: 0.0225 - train_acc: 1.0000 - test_acc: 0.9756\n",
      "Epoch 14/30 - loss: 0.0194 - train_acc: 1.0000 - test_acc: 0.9778\n",
      "Epoch 15/30 - loss: 0.0171 - train_acc: 1.0000 - test_acc: 0.9756\n",
      "Epoch 16/30 - loss: 0.0148 - train_acc: 1.0000 - test_acc: 0.9756\n",
      "Epoch 17/30 - loss: 0.0132 - train_acc: 1.0000 - test_acc: 0.9756\n",
      "Epoch 18/30 - loss: 0.0119 - train_acc: 1.0000 - test_acc: 0.9756\n",
      "Epoch 19/30 - loss: 0.0107 - train_acc: 1.0000 - test_acc: 0.9756\n",
      "Epoch 20/30 - loss: 0.0099 - train_acc: 1.0000 - test_acc: 0.9756\n",
      "Epoch 21/30 - loss: 0.0093 - train_acc: 1.0000 - test_acc: 0.9756\n",
      "Epoch 22/30 - loss: 0.0084 - train_acc: 1.0000 - test_acc: 0.9756\n",
      "Epoch 23/30 - loss: 0.0078 - train_acc: 1.0000 - test_acc: 0.9756\n",
      "Epoch 24/30 - loss: 0.0072 - train_acc: 1.0000 - test_acc: 0.9756\n",
      "Epoch 25/30 - loss: 0.0068 - train_acc: 1.0000 - test_acc: 0.9756\n",
      "Epoch 26/30 - loss: 0.0062 - train_acc: 1.0000 - test_acc: 0.9756\n",
      "Epoch 27/30 - loss: 0.0059 - train_acc: 1.0000 - test_acc: 0.9756\n",
      "Epoch 28/30 - loss: 0.0056 - train_acc: 1.0000 - test_acc: 0.9756\n",
      "Epoch 29/30 - loss: 0.0052 - train_acc: 1.0000 - test_acc: 0.9756\n",
      "Epoch 30/30 - loss: 0.0050 - train_acc: 1.0000 - test_acc: 0.9756\n",
      "Training model with 26122 parameters\n",
      "Epoch 1/30 - loss: 2.1490 - train_acc: 0.7209 - test_acc: 0.7133\n",
      "Epoch 2/30 - loss: 1.2239 - train_acc: 0.8411 - test_acc: 0.8222\n",
      "Epoch 3/30 - loss: 0.4425 - train_acc: 0.9436 - test_acc: 0.9267\n",
      "Epoch 4/30 - loss: 0.2221 - train_acc: 0.9673 - test_acc: 0.9400\n",
      "Epoch 5/30 - loss: 0.1429 - train_acc: 0.9777 - test_acc: 0.9511\n",
      "Epoch 6/30 - loss: 0.1012 - train_acc: 0.9874 - test_acc: 0.9667\n",
      "Epoch 7/30 - loss: 0.0883 - train_acc: 0.9889 - test_acc: 0.9667\n",
      "Epoch 8/30 - loss: 0.0657 - train_acc: 0.9911 - test_acc: 0.9622\n",
      "Epoch 9/30 - loss: 0.0504 - train_acc: 0.9948 - test_acc: 0.9689\n",
      "Epoch 10/30 - loss: 0.0423 - train_acc: 0.9970 - test_acc: 0.9689\n",
      "Epoch 11/30 - loss: 0.0344 - train_acc: 0.9978 - test_acc: 0.9689\n",
      "Epoch 12/30 - loss: 0.0285 - train_acc: 0.9985 - test_acc: 0.9667\n",
      "Epoch 13/30 - loss: 0.0250 - train_acc: 1.0000 - test_acc: 0.9689\n",
      "Epoch 14/30 - loss: 0.0212 - train_acc: 1.0000 - test_acc: 0.9711\n",
      "Epoch 15/30 - loss: 0.0186 - train_acc: 1.0000 - test_acc: 0.9711\n",
      "Epoch 16/30 - loss: 0.0160 - train_acc: 1.0000 - test_acc: 0.9689\n",
      "Epoch 17/30 - loss: 0.0142 - train_acc: 1.0000 - test_acc: 0.9689\n",
      "Epoch 18/30 - loss: 0.0127 - train_acc: 1.0000 - test_acc: 0.9711\n",
      "Epoch 19/30 - loss: 0.0114 - train_acc: 1.0000 - test_acc: 0.9711\n",
      "Epoch 20/30 - loss: 0.0112 - train_acc: 1.0000 - test_acc: 0.9689\n",
      "Epoch 21/30 - loss: 0.0098 - train_acc: 1.0000 - test_acc: 0.9689\n",
      "Epoch 22/30 - loss: 0.0089 - train_acc: 1.0000 - test_acc: 0.9711\n",
      "Epoch 23/30 - loss: 0.0081 - train_acc: 1.0000 - test_acc: 0.9711\n",
      "Epoch 24/30 - loss: 0.0081 - train_acc: 1.0000 - test_acc: 0.9711\n",
      "Epoch 25/30 - loss: 0.0076 - train_acc: 1.0000 - test_acc: 0.9711\n",
      "Epoch 26/30 - loss: 0.0067 - train_acc: 1.0000 - test_acc: 0.9711\n",
      "Epoch 27/30 - loss: 0.0061 - train_acc: 1.0000 - test_acc: 0.9711\n",
      "Epoch 28/30 - loss: 0.0057 - train_acc: 1.0000 - test_acc: 0.9711\n",
      "Epoch 29/30 - loss: 0.0053 - train_acc: 1.0000 - test_acc: 0.9711\n",
      "Epoch 30/30 - loss: 0.0050 - train_acc: 1.0000 - test_acc: 0.9711\n",
      "Training model with 44170 parameters\n",
      "Epoch 1/30 - loss: 1.7318 - train_acc: 0.8330 - test_acc: 0.8089\n",
      "Epoch 2/30 - loss: 0.4757 - train_acc: 0.9547 - test_acc: 0.9311\n",
      "Epoch 3/30 - loss: 0.2126 - train_acc: 0.9740 - test_acc: 0.9644\n",
      "Epoch 4/30 - loss: 0.1583 - train_acc: 0.9889 - test_acc: 0.9756\n",
      "Epoch 5/30 - loss: 0.1025 - train_acc: 0.9933 - test_acc: 0.9733\n",
      "Epoch 6/30 - loss: 0.1254 - train_acc: 0.9970 - test_acc: 0.9800\n",
      "Epoch 7/30 - loss: 0.0873 - train_acc: 0.9963 - test_acc: 0.9711\n",
      "Epoch 8/30 - loss: 0.0876 - train_acc: 0.9978 - test_acc: 0.9756\n",
      "Epoch 9/30 - loss: 0.0856 - train_acc: 0.9985 - test_acc: 0.9778\n",
      "Epoch 10/30 - loss: 0.0684 - train_acc: 0.9993 - test_acc: 0.9756\n",
      "Epoch 11/30 - loss: 0.0712 - train_acc: 0.9993 - test_acc: 0.9711\n",
      "Epoch 12/30 - loss: 0.0585 - train_acc: 1.0000 - test_acc: 0.9822\n",
      "Epoch 13/30 - loss: 0.0708 - train_acc: 0.9993 - test_acc: 0.9711\n",
      "Epoch 14/30 - loss: 0.0850 - train_acc: 1.0000 - test_acc: 0.9711\n",
      "Epoch 15/30 - loss: 0.0522 - train_acc: 1.0000 - test_acc: 0.9756\n",
      "Epoch 16/30 - loss: 0.0875 - train_acc: 0.9993 - test_acc: 0.9667\n",
      "Epoch 17/30 - loss: 0.1067 - train_acc: 1.0000 - test_acc: 0.9733\n",
      "Epoch 18/30 - loss: 0.0602 - train_acc: 1.0000 - test_acc: 0.9711\n",
      "Epoch 19/30 - loss: 0.0269 - train_acc: 1.0000 - test_acc: 0.9756\n",
      "Epoch 20/30 - loss: 0.0425 - train_acc: 1.0000 - test_acc: 0.9689\n",
      "Epoch 21/30 - loss: 0.0823 - train_acc: 0.9985 - test_acc: 0.9578\n",
      "Epoch 22/30 - loss: 0.0784 - train_acc: 0.9993 - test_acc: 0.9778\n",
      "Epoch 23/30 - loss: 0.0813 - train_acc: 0.9993 - test_acc: 0.9733\n",
      "Epoch 24/30 - loss: 0.0561 - train_acc: 0.9993 - test_acc: 0.9822\n",
      "Epoch 25/30 - loss: 0.1005 - train_acc: 0.9993 - test_acc: 0.9778\n",
      "Epoch 26/30 - loss: 0.0785 - train_acc: 0.9978 - test_acc: 0.9733\n",
      "Epoch 27/30 - loss: 0.1643 - train_acc: 1.0000 - test_acc: 0.9778\n",
      "Epoch 28/30 - loss: 0.1636 - train_acc: 0.9970 - test_acc: 0.9600\n",
      "Epoch 29/30 - loss: 0.0744 - train_acc: 0.9985 - test_acc: 0.9733\n",
      "Epoch 30/30 - loss: 0.0490 - train_acc: 0.9978 - test_acc: 0.9711\n",
      "Training model with 50826 parameters\n",
      "Epoch 1/30 - loss: 2.0507 - train_acc: 0.7558 - test_acc: 0.7222\n",
      "Epoch 2/30 - loss: 0.9483 - train_acc: 0.9079 - test_acc: 0.8644\n",
      "Epoch 3/30 - loss: 0.3619 - train_acc: 0.9495 - test_acc: 0.9267\n",
      "Epoch 4/30 - loss: 0.2076 - train_acc: 0.9659 - test_acc: 0.9533\n",
      "Epoch 5/30 - loss: 0.1358 - train_acc: 0.9770 - test_acc: 0.9644\n",
      "Epoch 6/30 - loss: 0.1062 - train_acc: 0.9881 - test_acc: 0.9644\n",
      "Epoch 7/30 - loss: 0.0857 - train_acc: 0.9941 - test_acc: 0.9733\n",
      "Epoch 8/30 - loss: 0.0734 - train_acc: 0.9970 - test_acc: 0.9689\n",
      "Epoch 9/30 - loss: 0.0714 - train_acc: 0.9970 - test_acc: 0.9800\n",
      "Epoch 10/30 - loss: 0.0527 - train_acc: 0.9985 - test_acc: 0.9756\n",
      "Epoch 11/30 - loss: 0.0374 - train_acc: 0.9985 - test_acc: 0.9756\n",
      "Epoch 12/30 - loss: 0.0326 - train_acc: 0.9993 - test_acc: 0.9822\n",
      "Epoch 13/30 - loss: 0.0270 - train_acc: 0.9993 - test_acc: 0.9800\n",
      "Epoch 14/30 - loss: 0.0240 - train_acc: 0.9993 - test_acc: 0.9756\n",
      "Epoch 15/30 - loss: 0.0228 - train_acc: 1.0000 - test_acc: 0.9778\n",
      "Epoch 16/30 - loss: 0.0224 - train_acc: 1.0000 - test_acc: 0.9822\n",
      "Epoch 17/30 - loss: 0.0190 - train_acc: 1.0000 - test_acc: 0.9800\n",
      "Epoch 18/30 - loss: 0.0189 - train_acc: 1.0000 - test_acc: 0.9822\n",
      "Epoch 19/30 - loss: 0.0170 - train_acc: 1.0000 - test_acc: 0.9822\n",
      "Epoch 20/30 - loss: 0.0142 - train_acc: 1.0000 - test_acc: 0.9800\n",
      "Epoch 21/30 - loss: 0.0151 - train_acc: 1.0000 - test_acc: 0.9756\n",
      "Epoch 22/30 - loss: 0.0132 - train_acc: 1.0000 - test_acc: 0.9822\n",
      "Epoch 23/30 - loss: 0.0124 - train_acc: 1.0000 - test_acc: 0.9800\n",
      "Epoch 24/30 - loss: 0.0108 - train_acc: 1.0000 - test_acc: 0.9822\n",
      "Epoch 25/30 - loss: 0.0107 - train_acc: 1.0000 - test_acc: 0.9822\n",
      "Epoch 26/30 - loss: 0.0107 - train_acc: 1.0000 - test_acc: 0.9800\n",
      "Epoch 27/30 - loss: 0.0086 - train_acc: 1.0000 - test_acc: 0.9756\n",
      "Epoch 28/30 - loss: 0.0094 - train_acc: 1.0000 - test_acc: 0.9778\n",
      "Epoch 29/30 - loss: 0.0086 - train_acc: 1.0000 - test_acc: 0.9778\n",
      "Epoch 30/30 - loss: 0.0082 - train_acc: 1.0000 - test_acc: 0.9778\n",
      "Training model with 116618 parameters\n",
      "Epoch 1/30 - loss: 2.2658 - train_acc: 0.6496 - test_acc: 0.6311\n",
      "Epoch 2/30 - loss: 1.9014 - train_acc: 0.7639 - test_acc: 0.7467\n",
      "Epoch 3/30 - loss: 0.8167 - train_acc: 0.8968 - test_acc: 0.8733\n",
      "Epoch 4/30 - loss: 0.3128 - train_acc: 0.9555 - test_acc: 0.9089\n",
      "Epoch 5/30 - loss: 0.1654 - train_acc: 0.9725 - test_acc: 0.9356\n",
      "Epoch 6/30 - loss: 0.1041 - train_acc: 0.9859 - test_acc: 0.9578\n",
      "Epoch 7/30 - loss: 0.0668 - train_acc: 0.9896 - test_acc: 0.9511\n",
      "Epoch 8/30 - loss: 0.0492 - train_acc: 0.9970 - test_acc: 0.9578\n",
      "Epoch 9/30 - loss: 0.0338 - train_acc: 0.9978 - test_acc: 0.9578\n",
      "Epoch 10/30 - loss: 0.0259 - train_acc: 1.0000 - test_acc: 0.9622\n",
      "Epoch 11/30 - loss: 0.0188 - train_acc: 1.0000 - test_acc: 0.9600\n",
      "Epoch 12/30 - loss: 0.0183 - train_acc: 0.9993 - test_acc: 0.9689\n",
      "Epoch 13/30 - loss: 0.0217 - train_acc: 1.0000 - test_acc: 0.9667\n",
      "Epoch 14/30 - loss: 0.0112 - train_acc: 1.0000 - test_acc: 0.9711\n",
      "Epoch 15/30 - loss: 0.0086 - train_acc: 1.0000 - test_acc: 0.9689\n",
      "Epoch 16/30 - loss: 0.0073 - train_acc: 1.0000 - test_acc: 0.9711\n",
      "Epoch 17/30 - loss: 0.0064 - train_acc: 1.0000 - test_acc: 0.9689\n",
      "Epoch 18/30 - loss: 0.0061 - train_acc: 1.0000 - test_acc: 0.9711\n",
      "Epoch 19/30 - loss: 0.0051 - train_acc: 1.0000 - test_acc: 0.9667\n",
      "Epoch 20/30 - loss: 0.0045 - train_acc: 1.0000 - test_acc: 0.9689\n",
      "Epoch 21/30 - loss: 0.0040 - train_acc: 1.0000 - test_acc: 0.9689\n",
      "Epoch 22/30 - loss: 0.0037 - train_acc: 1.0000 - test_acc: 0.9689\n",
      "Epoch 23/30 - loss: 0.0036 - train_acc: 1.0000 - test_acc: 0.9689\n",
      "Epoch 24/30 - loss: 0.0034 - train_acc: 1.0000 - test_acc: 0.9689\n",
      "Epoch 25/30 - loss: 0.0030 - train_acc: 1.0000 - test_acc: 0.9689\n",
      "Epoch 26/30 - loss: 0.0028 - train_acc: 1.0000 - test_acc: 0.9689\n",
      "Epoch 27/30 - loss: 0.0028 - train_acc: 1.0000 - test_acc: 0.9689\n",
      "Epoch 28/30 - loss: 0.0024 - train_acc: 1.0000 - test_acc: 0.9689\n",
      "Epoch 29/30 - loss: 0.0022 - train_acc: 1.0000 - test_acc: 0.9689\n",
      "Epoch 30/30 - loss: 0.0022 - train_acc: 1.0000 - test_acc: 0.9689\n",
      "Training model with 199818 parameters\n",
      "Epoch 1/30 - loss: 2.0815 - train_acc: 0.7958 - test_acc: 0.7622\n",
      "Epoch 2/30 - loss: 0.8131 - train_acc: 0.9169 - test_acc: 0.8867\n",
      "Epoch 3/30 - loss: 0.3137 - train_acc: 0.9599 - test_acc: 0.9178\n",
      "Epoch 4/30 - loss: 0.2237 - train_acc: 0.9866 - test_acc: 0.9622\n",
      "Epoch 5/30 - loss: 0.1783 - train_acc: 0.9903 - test_acc: 0.9778\n",
      "Epoch 6/30 - loss: 0.1651 - train_acc: 0.9926 - test_acc: 0.9711\n",
      "Epoch 7/30 - loss: 0.1617 - train_acc: 0.9852 - test_acc: 0.9622\n",
      "Epoch 8/30 - loss: 0.1468 - train_acc: 0.9985 - test_acc: 0.9756\n",
      "Epoch 9/30 - loss: 0.1323 - train_acc: 0.9955 - test_acc: 0.9689\n",
      "Epoch 10/30 - loss: 0.0587 - train_acc: 0.9993 - test_acc: 0.9800\n",
      "Epoch 11/30 - loss: 0.0992 - train_acc: 0.9985 - test_acc: 0.9800\n",
      "Epoch 12/30 - loss: 0.0581 - train_acc: 1.0000 - test_acc: 0.9844\n",
      "Epoch 13/30 - loss: 0.0772 - train_acc: 0.9985 - test_acc: 0.9822\n",
      "Epoch 14/30 - loss: 0.0991 - train_acc: 0.9978 - test_acc: 0.9822\n",
      "Epoch 15/30 - loss: 0.0708 - train_acc: 0.9985 - test_acc: 0.9778\n",
      "Epoch 16/30 - loss: 0.0937 - train_acc: 1.0000 - test_acc: 0.9822\n",
      "Epoch 17/30 - loss: 0.0902 - train_acc: 0.9978 - test_acc: 0.9711\n",
      "Epoch 18/30 - loss: 0.0953 - train_acc: 0.9993 - test_acc: 0.9733\n",
      "Epoch 19/30 - loss: 0.0849 - train_acc: 0.9970 - test_acc: 0.9711\n",
      "Epoch 20/30 - loss: 0.0799 - train_acc: 0.9993 - test_acc: 0.9756\n",
      "Epoch 21/30 - loss: 0.0838 - train_acc: 1.0000 - test_acc: 0.9756\n",
      "Epoch 22/30 - loss: 0.0416 - train_acc: 1.0000 - test_acc: 0.9733\n",
      "Epoch 23/30 - loss: 0.0956 - train_acc: 0.9955 - test_acc: 0.9844\n",
      "Epoch 24/30 - loss: 0.0666 - train_acc: 1.0000 - test_acc: 0.9867\n",
      "Epoch 25/30 - loss: 0.0745 - train_acc: 1.0000 - test_acc: 0.9667\n",
      "Epoch 26/30 - loss: 0.0263 - train_acc: 1.0000 - test_acc: 0.9844\n",
      "Epoch 27/30 - loss: 0.0516 - train_acc: 1.0000 - test_acc: 0.9778\n",
      "Epoch 28/30 - loss: 0.1074 - train_acc: 1.0000 - test_acc: 0.9778\n",
      "Epoch 29/30 - loss: 0.0568 - train_acc: 0.9993 - test_acc: 0.9800\n",
      "Epoch 30/30 - loss: 0.0185 - train_acc: 1.0000 - test_acc: 0.9844\n",
      "Training model with 461450 parameters\n",
      "Epoch 1/30 - loss: 2.2640 - train_acc: 0.6993 - test_acc: 0.6800\n",
      "Epoch 2/30 - loss: 1.8891 - train_acc: 0.7595 - test_acc: 0.7400\n",
      "Epoch 3/30 - loss: 0.6976 - train_acc: 0.9220 - test_acc: 0.8933\n",
      "Epoch 4/30 - loss: 0.2402 - train_acc: 0.9510 - test_acc: 0.9156\n",
      "Epoch 5/30 - loss: 0.1314 - train_acc: 0.9866 - test_acc: 0.9444\n",
      "Epoch 6/30 - loss: 0.0665 - train_acc: 0.9933 - test_acc: 0.9556\n",
      "Epoch 7/30 - loss: 0.0360 - train_acc: 0.9970 - test_acc: 0.9689\n",
      "Epoch 8/30 - loss: 0.0220 - train_acc: 0.9993 - test_acc: 0.9578\n",
      "Epoch 9/30 - loss: 0.0171 - train_acc: 1.0000 - test_acc: 0.9644\n",
      "Epoch 10/30 - loss: 0.0111 - train_acc: 1.0000 - test_acc: 0.9667\n",
      "Epoch 11/30 - loss: 0.0080 - train_acc: 1.0000 - test_acc: 0.9711\n",
      "Epoch 12/30 - loss: 0.0064 - train_acc: 1.0000 - test_acc: 0.9711\n",
      "Epoch 13/30 - loss: 0.0058 - train_acc: 1.0000 - test_acc: 0.9711\n",
      "Epoch 14/30 - loss: 0.0053 - train_acc: 1.0000 - test_acc: 0.9711\n",
      "Epoch 15/30 - loss: 0.0041 - train_acc: 1.0000 - test_acc: 0.9711\n",
      "Epoch 16/30 - loss: 0.0034 - train_acc: 1.0000 - test_acc: 0.9733\n",
      "Epoch 17/30 - loss: 0.0030 - train_acc: 1.0000 - test_acc: 0.9733\n",
      "Epoch 18/30 - loss: 0.0028 - train_acc: 1.0000 - test_acc: 0.9733\n",
      "Epoch 19/30 - loss: 0.0026 - train_acc: 1.0000 - test_acc: 0.9733\n",
      "Epoch 20/30 - loss: 0.0023 - train_acc: 1.0000 - test_acc: 0.9733\n",
      "Epoch 21/30 - loss: 0.0021 - train_acc: 1.0000 - test_acc: 0.9733\n",
      "Epoch 22/30 - loss: 0.0019 - train_acc: 1.0000 - test_acc: 0.9733\n",
      "Epoch 23/30 - loss: 0.0018 - train_acc: 1.0000 - test_acc: 0.9733\n",
      "Epoch 24/30 - loss: 0.0016 - train_acc: 1.0000 - test_acc: 0.9733\n",
      "Epoch 25/30 - loss: 0.0016 - train_acc: 1.0000 - test_acc: 0.9733\n",
      "Epoch 26/30 - loss: 0.0014 - train_acc: 1.0000 - test_acc: 0.9733\n",
      "Epoch 27/30 - loss: 0.0014 - train_acc: 1.0000 - test_acc: 0.9733\n",
      "Epoch 28/30 - loss: 0.0013 - train_acc: 1.0000 - test_acc: 0.9733\n",
      "Epoch 29/30 - loss: 0.0013 - train_acc: 1.0000 - test_acc: 0.9733\n",
      "Epoch 30/30 - loss: 0.0011 - train_acc: 1.0000 - test_acc: 0.9733\n",
      "Training model with 758922 parameters\n",
      "Epoch 1/30 - loss: 2.2480 - train_acc: 0.6578 - test_acc: 0.6422\n",
      "Epoch 2/30 - loss: 1.4024 - train_acc: 0.8196 - test_acc: 0.7956\n",
      "Epoch 3/30 - loss: 0.4698 - train_acc: 0.8374 - test_acc: 0.8089\n",
      "Epoch 4/30 - loss: 0.5461 - train_acc: 0.9510 - test_acc: 0.9267\n",
      "Epoch 5/30 - loss: 0.2388 - train_acc: 0.9725 - test_acc: 0.9578\n",
      "Epoch 6/30 - loss: 0.1384 - train_acc: 0.9844 - test_acc: 0.9622\n",
      "Epoch 7/30 - loss: 0.0877 - train_acc: 0.9926 - test_acc: 0.9644\n",
      "Epoch 8/30 - loss: 0.0613 - train_acc: 0.9941 - test_acc: 0.9711\n",
      "Epoch 9/30 - loss: 0.0662 - train_acc: 0.9985 - test_acc: 0.9667\n",
      "Epoch 10/30 - loss: 0.0500 - train_acc: 0.9955 - test_acc: 0.9733\n",
      "Epoch 11/30 - loss: 0.0968 - train_acc: 0.9970 - test_acc: 0.9711\n",
      "Epoch 12/30 - loss: 0.1213 - train_acc: 0.9955 - test_acc: 0.9667\n",
      "Epoch 13/30 - loss: 0.0958 - train_acc: 1.0000 - test_acc: 0.9800\n",
      "Epoch 14/30 - loss: 0.0788 - train_acc: 0.9993 - test_acc: 0.9756\n",
      "Epoch 15/30 - loss: 0.1120 - train_acc: 0.9970 - test_acc: 0.9778\n",
      "Epoch 16/30 - loss: 0.2172 - train_acc: 0.9978 - test_acc: 0.9644\n",
      "Epoch 17/30 - loss: 0.1262 - train_acc: 0.9985 - test_acc: 0.9644\n",
      "Epoch 18/30 - loss: 0.0904 - train_acc: 1.0000 - test_acc: 0.9733\n",
      "Epoch 19/30 - loss: 0.1211 - train_acc: 0.9993 - test_acc: 0.9756\n",
      "Epoch 20/30 - loss: 0.0754 - train_acc: 1.0000 - test_acc: 0.9756\n",
      "Epoch 21/30 - loss: 0.1880 - train_acc: 0.9978 - test_acc: 0.9778\n",
      "Epoch 22/30 - loss: 0.0650 - train_acc: 0.9993 - test_acc: 0.9689\n",
      "Epoch 23/30 - loss: 0.0842 - train_acc: 0.9993 - test_acc: 0.9711\n",
      "Epoch 24/30 - loss: 0.1024 - train_acc: 0.9993 - test_acc: 0.9711\n",
      "Epoch 25/30 - loss: 0.0442 - train_acc: 0.9993 - test_acc: 0.9756\n",
      "Epoch 26/30 - loss: 0.0253 - train_acc: 1.0000 - test_acc: 0.9756\n",
      "Epoch 27/30 - loss: 0.0574 - train_acc: 1.0000 - test_acc: 0.9756\n",
      "Epoch 28/30 - loss: 0.1262 - train_acc: 0.9985 - test_acc: 0.9711\n",
      "Epoch 29/30 - loss: 0.0920 - train_acc: 0.9993 - test_acc: 0.9622\n",
      "Epoch 30/30 - loss: 0.0511 - train_acc: 1.0000 - test_acc: 0.9733\n"
     ]
    }
   ],
   "source": [
    "models = get_models()\n",
    "\n",
    "Datas = []\n",
    "\n",
    "for i in range(len(models)) :\n",
    "    model = models[i] \n",
    "    print(\"Training model with {} parameters\".format(count_parameters(model)))\n",
    "    criterion = nn.CrossEntropyLoss()  \n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "\n",
    "    # create evaluation loaders (uses existing Xte_t, yte_t, train_set)\n",
    "    test_set = TensorDataset(Xte_t, yte_t)\n",
    "    test_loader = DataLoader(test_set, batch_size=256, shuffle=False)\n",
    "    train_eval_loader = DataLoader(train_set, batch_size=256, shuffle=False)\n",
    "\n",
    "    # Run training with real-time accuracy logging\n",
    "    n_epochs_monitor = 30  # number of epochs to run/continue training\n",
    "    for epoch in range(n_epochs_monitor):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        train_acc = evaluate(train_eval_loader, model)\n",
    "        test_acc = evaluate(test_loader, model)\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs_monitor} - loss: {avg_loss:.4f} - train_acc: {train_acc:.4f} - test_acc: {test_acc:.4f}\")\n",
    "\n",
    "    la = Laplace(model, 'classification',\n",
    "            subset_of_weights='all',\n",
    "            hessian_structure='diag',\n",
    "          )\n",
    "    la.fit(train_loader)\n",
    "    val = la.H.numpy()\n",
    "    Datas.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0a5a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Repetition 1/10 ===\n",
      "\n",
      "Training model with 650 parameters (repeat 1)\n",
      "\n",
      "Training model with 4810 parameters (repeat 1)\n",
      "\n",
      "Training model with 17226 parameters (repeat 1)\n",
      "\n",
      "Training model with 26122 parameters (repeat 1)\n",
      "\n",
      "Training model with 44170 parameters (repeat 1)\n",
      "\n",
      "Training model with 50826 parameters (repeat 1)\n",
      "\n",
      "Training model with 116618 parameters (repeat 1)\n"
     ]
    }
   ],
   "source": [
    "n_repeats = 10\n",
    "alpha = 0.9\n",
    "results = {}\n",
    "\n",
    "for repeat in range(n_repeats):\n",
    "    print(f\"\\n=== Repetition {repeat+1}/{n_repeats} ===\")\n",
    "    \n",
    "    # üí° Îß§ Î∞òÎ≥µÎßàÎã§ fresh initialization\n",
    "    models = get_models()\n",
    "\n",
    "    for model in models:\n",
    "        n_params = count_parameters(model)\n",
    "        x_val = np.log(n_params)\n",
    "\n",
    "        print(f\"\\nTraining model with {n_params} parameters (repeat {repeat+1})\")\n",
    "\n",
    "        torch.manual_seed(repeat)\n",
    "        np.random.seed(repeat)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "        train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "        test_loader = DataLoader(TensorDataset(Xte_t, yte_t), batch_size=256, shuffle=False)\n",
    "        train_eval_loader = DataLoader(train_set, batch_size=256, shuffle=False)\n",
    "\n",
    "        n_epochs_monitor = 30\n",
    "        for epoch in range(n_epochs_monitor):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "        # after training:\n",
    "        la = Laplace(model, 'classification', subset_of_weights='all', hessian_structure='diag')\n",
    "        la.fit(train_loader)\n",
    "        val = la.H.cpu().numpy()\n",
    "\n",
    "        ratio, idx = cumulative_explained_ratio(val, alpha=alpha)\n",
    "\n",
    "        # üíæ ratio + full eigenvalues Îëò Îã§ Ï†ÄÏû•\n",
    "        results.setdefault(x_val, []).append({\n",
    "            'ratio': ratio,\n",
    "            'eigenvalues': val\n",
    "        })\n",
    "\n",
    "with open(\"results_curvature_concentration.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dea7d430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Model Complexity vs. Curvature Concentration')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArwAAAIjCAYAAADhisjVAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWhNJREFUeJzt3QeUU+X29/E91BGkCAgzINIFkV5FUVC6SrFc0StSVFSuFaxcBQRUVBQrVxQFQSyoFzuigqKiIEpHioIoKr0XpTiTd/2e+yb/JJMZJtMyOfP9rBWYnHNy8uQkmdnZ2Wc/CT6fz2cAAACARxWK9QAAAACA3ETACwAAAE8j4AUAAICnEfACAADA0wh4AQAA4GkEvAAAAPA0Al4AAAB4GgEvAAAAPI2AFwAAAJ5GwAvkgYSEBLvvvvuivt0vv/zibvvSSy+Z11WvXt369++fa/vXMdSx1DEFkH8VpN97yDsEvCgw/AGPLvPmzUuzXrNsV61a1a2/4IILLB5t3brVbr/9dqtXr56VKFHCSpYsac2bN7f777/f9uzZE+vh5Tv/+c9/PPVH9dChQ/b4449b69atrUyZMpaYmGinnHKK3Xjjjfbjjz9afrZp0yb3oXDp0qWWX+3bt89GjhxpjRs3tuOPP96OO+44a9Cggd11111u/F6T28/Jq6++ak888USu7BsIVyTNEsDjFAToF23btm1Dln/xxRf2+++/W/HixS0efffdd3beeefZgQMHrE+fPi7Qle+//94eeugh+/LLL+2TTz6xgurKK6+0yy67LOT5VcBboUKFXM0s55UdO3ZY165dbdGiRe4D2z//+U8XlK1du9Zef/11e/755+3IkSOWn4MrBZPK9Ddp0sTym59//tk6duxoGzdutH/84x927bXXWrFixWz58uX24osv2ttvv53vP1Tkt+dEv4dXrlxpt956a8jyatWq2V9//WVFixbN8ftEwUXAiwJHQeGbb75pTz31lBUpUiTkl6+CRAUO8UbZ2wsvvNAKFy5sS5YscRneYA888IBNnDjRCjIdG128SkG7nvu33nrLLr744pB1o0ePtnvuuSdH7ufvv/+21NRUF+zFS9ZbYy1UqFC2HvNFF13kvkGZO3dumg/Len89/PDDVtD9+eef7pul7NK3bEpMADnKBxQQkydP9ukl/+abb/oSEhJ8M2fODKw7fPiw74QTTvA99thjvmrVqvnOP//8kNseOHDAN2TIEN9JJ53kK1asmO+UU07xjR071peamhqy3aFDh3y33nqrr0KFCr7jjz/e1717d99vv/3m7nfEiBEh2/7+++++AQMG+CpWrOj2Wb9+fd+LL74Yss2GDRvcbTX2jDz00ENuu1deeSXTx2P8+PHuPnXfycnJvn/961++3bt3h2zTrl0732mnneZbtmyZ7+yzz/Ydd9xxvlq1arljKHPnzvW1atXKl5iY6I7Jp59+GnJ7PWaNa/Xq1b5//OMfvlKlSvnKlSvnu/nmm31//fVXyLY67v369QtZpvHccsstgeOu+9ZjTUlJcet1/Nu3b++O99atW0OezwYNGvhq1qzpnrvg51/H1H9/uh580eNdv369+3ncuHFpjtnXX3/t1r366qsRj+mWLVt8hQsX9t13331p1q1Zs8bd9umnn3bXjxw54rarXbu2r3jx4u64nHnmmb5PPvnEF60FCxa4fQ8cODBT2+tx6hJOx1/HJfz1p9f6448/7o5noUKF3P1l9nHu3LnTd9ttt7nno2TJku410LVrV9/SpUsDt/n888/TPBfBr/tIr41Ij8O/n9dee813zz33+CpXruze6/7XtcbdpUsXX+nSpd1rWa/pefPmHfN4vf76626/DzzwgC+z3njjDV+zZs3ce6N8+fK+K664wr3ng+kx6Zhoec+ePd3Pei3reP39998h2+o1/8QTT7jjqNeLttNj+e6770K2e/nllwP3q99pvXv39m3cuDHi+/qHH35w7x8dCx2rhx9+ONPPiX8f33//ve+ss85y+9B7Vd555x3feeed536v6H2r182oUaNCHpNuH75v/2svvd97c+bM8bVt29ZXokQJX5kyZXw9evTwrVq1KuLvnJ9++skdX22n57t///6+gwcPZvr5g/dQw4sCR1/PtWnTxl577bXAso8++sj27t3rvvKOVNvbo0cPVxupr4zHjRtndevWtTvuuMOGDBkSsu0111zjatI6d+7sygj0ldz555+fZp/KFJ1++uk2e/ZsV1/55JNPWu3ate3qq6/OUk3be++95+oJL7nkkkxtr7q8G264wSpXrmyPPfaYywg+99xzbtxHjx4N2Xb37t3uK3LVhT7yyCOuJEDHafr06e5/Zcz1WA8ePOjuf//+/Wnu79JLL3WZtjFjxrjtlV3XV8LHyha1a9fOpk2bZn379nW3OfPMM23o0KGB465M0KRJk9y+r7/++sBtR4wYYT/88INNnjzZ1TFHouN80kknuWz4yy+/7C7KgtasWdPdzyuvvJLmNlpWqlQp69mzZ8R9VqpUyY35jTfeSLNOx0sZZn0d7n8O9HXxOeecY88884y775NPPtkWL15sWXn+/WUbuUHH8emnn3bPmV4vycnJmX6cKgV455133GtI7x29b1asWOFu7697PfXUU23UqFHuZ92H//k4++yzszReZbQ//PBDV8/+4IMPugzvZ5995vanOly9PrRc34yce+65tnDhwhw9vqoL12tex0Gv+YEDB9qMGTNcZji8lj4lJcW6dOli5cuXt0cffdQdFx1jlaAE0+8GffWv8wyUTb777rtdFnTBggUhmWa9V+rUqeOOtbafM2eOe9zh96v3tX6fqR5Z96f3gWqR9bsws8/Jzp07rVu3bq7cQe8nvZb9j1/lNHqf6nebvjkbPny4G7OfXu+6nUqK/PvO6HefflfqOG3bts29d7Tvb775xr1XI52IquOv30U6/vpZY9L7DQVYrCNuIK/4M3zKiDzzzDMu0/Tnn3+6dco+nnPOOe7n8AyvshW63f333x+yv0suucRlj9atW+euK2Ol7ZQpDfbPf/4zTYb36quvdtmPHTt2hGx72WWXuYyEf1yZzfAqk9O4ceNMHYdt27a5rEvnzp0DmVLRMdF9TZo0KU0WJjij6c/g+TN9fh9//HGasfqzLcrEBNMx0nJljv3Cs3ijR492Ga8ff/wx5LZ33323yy4GZ62ee+45t79p06YFso/KtAcLz/CKMlSRMp3+/Skz7aeMrLJqkTKNkW67YsWKkOXKpp977rmB63q+wr9JyKoLL7zQ3Wd4hj6nMrzKkOl1k5XHqW89gl9n/v0qS6msn5/el+m91qPN8Cqj6H8P+b8JqFOnjsuIBn8ro21q1Kjh69Spky8jTZs2de/LzNDrRN/aKBMb/C3GBx984MY2fPjwwDI9Ji0LPg7++2vevHng+meffea20zcj4fyP55dffnGv+/AstJ6fIkWKhCz3v6+nTp0a8q1IUlKS7+KLL87Uc+Lfx4QJE9KsCz72ftddd53LzOr14KfXf/DrzS/S770mTZq446pvDPz0+0O/h/r27Zvmd85VV12V5j2iTDsKLjK8KJD0iV8nRXzwwQcuC6D/dZJPJDNnznSZmptvvjlk+W233eayv/6MiLaT8O3CT8jQbf773/9a9+7d3c+qGfZflMFQpjnaLJ+yVso8ZoYyJTp5SeMKrmtUFqp06dIuMxZMmZrgzLey22XLlnUZIGV9/fw/K6MXTtnkYDfddFPIMYtEddZnnXWWnXDCCSHHSCcOKSumk/D8lIHSsdN+lYWrVauWy+Bl5/Wh7Flwlvfjjz92968TAjOiWk/VhivT6acTc1atWmW9e/cOLNMxVBb6p59+suzS8y+ZfQ1ES98AnHjiiVl6nPpGwP860/OmrKBeU3odZSWbnRn9+vVz33j4qcuAjrPe47p//2tJ30p06NDBvZZUl5wT7y+dJKos5L/+9a+QOlR906Msavj7S4K/nRC97oPfR/p9oW8zlJkOp+WiDLIeg167we+XpKQkl/H9/PPPQ26n5yD4tawseKtWrSK+f9Oj53bAgAFplgcfe/1+1Tj0mPStzZo1ayxamzdvds+h6tTLlSsXWN6oUSPr1KlTxN8jkY6pnnv/ewUFDwEvCiT98VbgpBPV9IdCf4jTKwf49ddf3Vf/4X/wFPD51/v/1x92BVvB9Ic92Pbt293Xi/rKUuMIvvj/eOgPZjQUqEYqJUjv8UQal/7g6et8/3o/fe3v/6Pqp5ZX+mo1fJn/q9Jw+oMbTMdIxyqjnrgKUGbNmpXmGOl5i3SMdKa8/qDqdvr6MviPbrQUjOoDiV4ffgp+q1Sp4r4Cz4i+olUQFfx1v4JCBYcKEv30dbFeB2ob1rBhQ/dVv874zwo9/5LZ10C0atSokeXHqSBM5UB6DShA0u30POqx6sNdXozX/6FCgXD46+mFF16ww4cPZziWnHh/iQLe8PeXguLwDxP6kBf8Plq/fr37HRQc7IXTY9QHaB3n8Me4evXqNO+XSO/r8Ps9Fr0fIp28qA9yOolWvxN07DQGf3Cdlec8o2Oq38P+Dy/BVB4U/tgkmscHb6FLAwosZXuU1dyyZYurQ1OQkxf8mST9AdAf4EiUuYiG/pAqA6LMbU6fPZ9eZ4P0luuP7rGE/6FN7zgpe3PnnXdGXK9AMZjOnlfgIqoRVZ12dqgWUllm1QkqIFUdp7J2mTnbXxlxfXjRc6I6RQWFCg4V7PmpFlKBzLvvvuvaxSnwUmA4YcIEVwseDX9XDj1uZbIyc/wjPU/64BdJeh8eMvM4lWkfNmyYXXXVVa62VkGbjqG+Ycgoqxo+3kg03kivw/Dx+u9n7Nix6bbXUsYzo+OrDhi//fZbmg962ZVTnUP0GHWc9I1TpH2GP77svH8zel3oQ5zqkBXo6kOdPtwqqFc2XzXCmX3OsysnHh+8hYAXBZYyENddd5076SP4a9lw6gmpMgBleIKzvP6v5rTe/79+mSuICc5EqA9qMGU7tB/9sfZnK7NL2cj58+e7rz4vv/zyDLf1j1fjUkbXT8Hyhg0bcmxM4dmn4KzbunXr3LHSCYTp0R9K9RTOzHj0lafKGXTSnQJ+naykEgf/Y81K4K0TevRcKbOrcg1ljzN70lKvXr3ca8v/ulJ/Vp1sF07BnwJGXfRYFQTrhJxoA149/zo5Ryf4ZSbgVbYr0lfX4dnHnHicapOmk5mUgQ8PjIID44yeC4030sQpGm/wazg9/m9dFIRl5fWt46uTXHV8Iz2P6b2/wr8N0LJjvSbTG79Kanbt2pVullfbKJjT+yz8w2BWZeaDaTh98FTpgL45Cz7BTb9bsrr/4GMaTr+H9TpK7+RUwI+SBhRYyng8++yzLsDQH7T0qKuAglOdSR9M2Tj9wlZ2WPz/q5tAsPAzj5V5UE2kglPVPIZTyUO0VK+mM+dVVxyp+b2+ztRsa6I/+AoKNc7gbIcCEn3dGKmrRHaNHz8+5LrO+A8+ZpGoFlFBvP7Qh1Pwo96ofsrUK4DWY1CpiL5W11ntx8rm6I9kejPQaR/68KCspUoklOXNbOZd3xYo4NZtNemDjreCw2AKCsJfj+rU4c9Si54P/UE/1tfAymYrQFeWWB0RwunDjD4EBAdH2m/wa23ZsmX29ddfZ+rxRfM49XoPfx6UOf/jjz9ClvkDlkjPh8arD6bBE2eo7l4Z18xQlwDtQ10Q9MEi2vecyp30/KsLgl6T4fRh2N/nuEWLFlaxYkWXqQ9+LpV5VWlBVt5f+n2hYxipy4D/2KqMRMda24Qfb10Pf71lRkbPybEyq8Fj0POmSV4i7T8zJQ763abM/JQpU0LGot+f+nZEv6OBYyHDiwItvZKCYAqGlaHSHzTVnKqNj37J6qtofS3rzx7pF7ICJP1i1y/xM844w7UEUjYznNp46SQSZQ4VrNWvX99lb/S1n7LJ+jkayoBppif94tc4gmda0z6VnfJ/xa+spbJU+sOoIEkt15Q50bhbtmx5zJOyskLZHd2P7k8BgzJlKinRsUyPalpVRqB2VjpZRY9HdXr62l5ZQz0XyuyoZZZOBFJQqrpEf0Ctx6EPNCpDSI/2qW30YUDBpgKV4Kycvx2anqtoJxbQiVsag46rgsLwkhk95+3bt3djUNZOJzvpcalNnZ+eU2V/9RiPNRvc1KlTXYZbgY9esyotUECh7LqCUWXBFfCJygvUtkrj0gcDfSBSgHbaaadFfVLPsR6nnj99ta3HofeEnj9lzcMzs3of6bYah74B0dj1/lDGUhlvHRu9fvRBSN+i6DUUXi+fHpVQ6MOAPmDpMWosqj9V0K3nVpnf999/P93bq72gMpb6sKispcagdlharnpV1XrrPaiAWMv0WtF96Kt9/U5QG0K159I3GoMHD7Zo6fePvl3Qa1HPp46DPuB99dVXbp1eMzoWeh3rva33hj546DjqvafXkU7sDP7QkxkZPSfp0XOsY6HfrTqBV0kBtRyL9OFTr319O6AWY/rdow996SUfVI6i50+/x/Sa1UnHep+rTlhJC+CYYt0mAohFW7KMRJp4Yv/+/b7Bgwe75uxFixZ1LY4iTTyhNkRqHaT2N2qpldHEE5oo4YYbbvBVrVrV7VMtgTp06OB7/vnnA9tkti2Z36ZNm9w4NQmEGs+rDZDaG6kl0d69e0O2VRuyevXqufuuVKmSb9CgQelOPJGZYyQaqx5TeIsgNYdXGze1glMLtRtvvDFTE0/ouA8dOtRNzqBWamoLdsYZZ/geffRR1/5Jx1btonScw6kNkZ6Dn3/+Od22ZJooQo9D4/JPPBFOj1+tj8InDTiWffv2uWb8/nZp4dTmTpN2lC1b1m2n50LPkx6Xn3/MmX3+1Q5Kx6Zly5Zu4hMdM71Wb7rppkD7PD+NSe27tI1aPqmtXEYTT2T1caoNlSZSUBs+bafJNebPnx+xNdq7777r2pqpjVb449akMFWqVHHtzLQPTXiQXlsy/8Qo4ZYsWeK76KKL3PtT+9FjvfTSS92EBpmh94faijVs2NC9t/QeU/sxvUY3b94csu306dNdezH/pCIZTTwRzv++CaZJG/Q86HWi5+zEE0/0devWzbdo0aKQ7f773/+6yRm0X120vd6Ta9euPeb7Ovz5z+g5SW8f/glaTj/99MCEFnfeeWegbaGeIz9NCqO2jXoPZGbiidmzZ7vnXvtVqzy979ObeGL79u0hyyO9/1GwJOifY4fFABA9/+QK+so4uF4znjRt2tRlYJWtBwDEJ2p4ASAdKjNQBwKVNgAA4hc1vAAQRifDLFq0KDCNbvBECgCA+EOGFwDC6AQpnXR09OhRd8Jf8IxZAID4Qw0vAAAAPI0MLwAAADyNgBcAAACexklrEaih96ZNm1yj7axMrQgAAIDcpapczXRYuXJlN8FMRgh4I1CwW7Vq1VgPAwAAAMegacb9M22mh4A3AmV2/QdQU04CAAAgf9FU6EpQ+uO2jBDwRuAvY1CwS8ALAACQf2Wm/JST1gAAAOBpBLwAAADwNAJeAAAAeBoBLwAAADyNgBcAAACeRsALAAAATyPgBQAAgKcR8AIAAMDTCHgBAADgaQS8AAAA8DQCXgAAAHgaAS8AAAA8jYAXAAAAnlYk1gMo6FJSfbZwwy7btv+QVSyVaK1qlLPChRJiPSwAAADPiHmGd/z48Va9enVLTEy01q1b28KFCzPcfs+ePXbDDTdYcnKyFS9e3E455RSbOXNmtvYZK7NWbra2D39ml09cYLe8vtT9r+taDgAAAA8EvNOnT7chQ4bYiBEjbPHixda4cWPr0qWLbdu2LeL2R44csU6dOtkvv/xib731lq1du9YmTpxoVapUyfI+Y0VB7aBpi23z3kMhy7fsPeSWE/QCAADkjASfz+ezGFH2tWXLlvbMM8+466mpqVa1alW76aab7O67706z/YQJE2zs2LG2Zs0aK1q0aI7sM5J9+/ZZmTJlbO/evVa6dGnLjTIGZXLDg10/FTQklUm0eXedS3kDAABANuO1mGV4la1dtGiRdezY8f8GU6iQuz5//vyIt3nvvfesTZs2rqShUqVK1qBBA3vwwQctJSUly/uUw4cPu4MWfMlNqtlNL9gVfQLRem0HAACA7IlZwLtjxw4XqCpwDabrW7ZsiXibn3/+2ZUy6Haq2x02bJg99thjdv/992d5nzJmzBj3CcF/UUY4N+kEtZzcDgAAAPn4pLVoqDyhYsWK9vzzz1vz5s2td+/eds8997hSh+wYOnSoS4f7L7/99pvlJnVjyMntAAAAkA/bklWoUMEKFy5sW7duDVmu60lJSRFvo84Mqt3V7fxOPfVUl71VOUNW9inq9qBLXlHrseQyie4ENV8GNbzaDgAAAHGa4S1WrJjL0s6ZMyckg6vrqtON5Mwzz7R169a57fx+/PFHFwhrf1nZZyzoRLQR3eu7n8NPSfNf13pOWAMAAIjzkga1D1NbsSlTptjq1att0KBBdvDgQRswYIBb37dvX1du4Kf1u3btsltuucUFuh9++KE7aU0nsWV2n/lF1wbJ9myfZi6TG0zXtVzrAQAAEOczrakGd/v27TZ8+HBXltCkSRObNWtW4KSzjRs3ui4LfjqZ7OOPP7bBgwdbo0aNXP9dBb933XVXpveZnyio7VQ/iZnWAAAAvNqHN7/K7T68AAAAKAB9eAEAAIC8QMALAAAATyPgBQAAgKcR8AIAAMDTCHgBAADgaQS8AAAA8DQCXgAAAHgaAS8AAAA8jYAXAAAAnkbACwAAAE8j4AUAAICnEfACAADA0wh4AQAA4GkEvAAAAPA0Al4AAAB4GgEvAAAAPI2AFwAAAJ5GwAsAAABPI+AFAACApxHwAgAAwNMIeAEAAOBpBLwAAADwNAJeAAAAeBoBLwAAADyNgBcAAACeRsALAAAATyPgBQAAgKcR8AIAAMDTCHgBAADgaQS8AAAA8DQCXgAAAHgaAS8AAAA8jYAXAAAAnkbACwAAAE8j4AUAAICnEfACAADA0wh4AQAA4GkEvAAAAPA0Al4AAAB4GgEvAAAAPI2AFwAAAJ5GwAsAAABPI+AFAACApxHwAgAAwNMIeAEAAOBpBLwAAADwNAJeAAAAeBoBLwAAADyNgBcAAACeRsALAAAATyPgBQAAgKcR8AIAAMDTCHgBAADgaQS8AAAA8DQCXgAAAHgaAS8AAAA8jYAXAAAAnkbACwAAAE8j4AUAAICnEfACAADA0wh4AQAA4GkEvAAAAPA0Al4AAAB4GgEvAAAAPI2AFwAAAJ5GwAsAAABPyxcB7/jx46169eqWmJhorVu3toULF6a77UsvvWQJCQkhF90uWP/+/dNs07Vr1zx4JAAAAMhvisR6ANOnT7chQ4bYhAkTXLD7xBNPWJcuXWzt2rVWsWLFiLcpXbq0W++ngDacAtzJkycHrhcvXjyXHgEAAADys5hneMeNG2cDBw60AQMGWP369V3gW6JECZs0aVK6t1GAm5SUFLhUqlQpzTYKcIO3OeGEE3L5kQAAACA/imnAe+TIEVu0aJF17Njx/wZUqJC7Pn/+/HRvd+DAAatWrZpVrVrVevbsaT/88EOabebOnesyxHXr1rVBgwbZzp07093f4cOHbd++fSEXAAAAeENMA94dO3ZYSkpKmgytrm/ZsiXibRTAKvv77rvv2rRp0yw1NdXOOOMM+/3330PKGaZOnWpz5syxhx9+2L744gvr1q2bu69IxowZY2XKlAlcFEgDAADAGxJ8Pp8vVne+adMmq1Klin3zzTfWpk2bwPI777zTBanffvvtMfdx9OhRO/XUU+3yyy+30aNHR9zm559/tlq1atns2bOtQ4cOETO8uvgpw6ugd+/eva5eGAAAAPmL4jUlKjMTr8U0w1uhQgUrXLiwbd26NWS5rqvuNjOKFi1qTZs2tXXr1qW7Tc2aNd19pbeN6n11oIIvAAAA8IaYBrzFihWz5s2bu9IDP5Uo6HpwxjcjKlNYsWKFJScnp7uNyh1Uw5vRNgAAAPCmmHdpUEuyiRMn2pQpU2z16tXuBLODBw+6rg3St29fGzp0aGD7UaNG2SeffOLKFBYvXmx9+vSxX3/91a655prACW133HGHLViwwH755RcXPOvEttq1a7t2ZwAAAChYYt6Ht3fv3rZ9+3YbPny4O1GtSZMmNmvWrMCJbBs3bnSdG/x2797t2phpW7UaU4ZYNcBqaSYqkVi+fLkLoPfs2WOVK1e2zp07u/peevECAAAUPDE9ac0LRdAAAADIe3Fz0hoAAACQ2wh4AQAA4GkEvAAAAPA0Al4AAAB4GgEvAAAAPI2AFwAAAJ5GwAsAAABPI+AFAACApxHwAgAAwNMIeAEAAOBp2Qp4Dx8+nHMjAQAAAGId8H700UfWr18/q1mzphUtWtRKlCjh5i5u166dPfDAA7Zp06bcGCMAAACQuwHv22+/baeccopdddVVVqRIEbvrrrtsxowZ9vHHH9sLL7zgAt7Zs2e7QPj666+37du3Z31EAAAAQA5K8Pl8vmNt1KZNG7v33nutW7duVqhQ+jHyH3/8YU8//bRVqlTJBg8ebPFq3759VqZMGdu7d6/LYAMAACB+47VMBbwFDQEvAACAd+K1bHdpOHjwoLtDAAAAID/KcsC7atUqa9GihZUqVcpOOOEEa9iwoX3//fc5OzoAAAAgVgHvddddZzfeeKMdOHDAdu7caRdddJHr4AAAAADEZcDbs2dPd1Kanzox9OjRw7UmK1u2rJ133nm2devW3BonAAAAkCVFMrthnz597Nxzz7UbbrjBbrrpJpfdPe2001xLsqNHj9pnn31mt912W9ZGAQAAAOSSqLo06Cw49eBdsmSJTZgwwfXknTt3rqWkpNiZZ55pLVu2NC+gSwMAAIB34rVMZ3hFO1WgO2/ePFev26lTJxs9erQrawAAAADi/qS1Xbt22aJFi1xHBv2vaLpp06Y2c+bM3BshAAAAkBcB76uvvmonnXSSnX/++VatWjX76KOPbMSIEfbuu+/aI488YpdeeiknrQEAACB+A96hQ4fapEmTbMuWLTZnzhwbNmyYW16vXj1Xx6vyBk1BDAAAAMRlwKt+u3Xr1nU/16pVy/7888+Q9QMHDrQFCxbk/AgBAACAbMj0SWs6SU3lDO3bt3czql155ZVptqlYsWJ2xgIAAADEti3Z+++/b2vWrLHGjRtb586dzatoSwYAAOCdeC2qgLegIOAFAAAooH14d+zY4U5cmz9/vjt5TZKSkuyMM86w/v3724knnpi9kQMAAACxOmntu+++s1NOOcWeeuopF02fffbZ7qKftUzdGlTbCwAAAOQnmS5pOP30013trmZaS0hICFmnXVx//fW2fPlyl/2Nd5Q0AAAAFMCShmXLltlLL72UJtgVLRs8eLCbdQ0AAACIy5IG1eouXLgw3fVaV6lSpZwaFwAAAJAjMp3hvf322+3aa6+1RYsWWYcOHQLBraYT1sxrEydOtEcffTRnRgUAAADkdcB7ww03WIUKFezxxx+3//znP5aSkuKWFy5c2Jo3b+7KHS699NKcGhcAAACQI7LUh/fo0aOuRZkoCC5atKh5CSetAQAAFNA+vH4KcJOTk7M6PgAAACD/nbTm79TQt29fq1mzph133HFWsmRJa9iwoQ0bNsxF2QAAAEDcBrwff/yxtWnTxv78808788wzrVChQnbVVVfZ+eefb6+//ro1a9YsMPsaAAAAEHc1vOqxe91117kJJuTTTz+1m2++2VavXu1qert162ZVq1a1yZMnW7yjhhcAAMA78VqmA16VMCi4rV69uruumxUvXtx+/fVXV8/71Vdf2cUXX2zbtm2zeEfACwAA4J14LdMlDVWqVLG1a9cGrq9fv95SU1OtfPny7vpJJ51kBw4cyM64AeSxlFSfzV+/095d+of7X9cBAPCaTHdp0Mlq11xzjd1zzz0usztu3Djr0aOHFStWzK1funSp1ahRIzfHCiAHzVq52Ua+v8o27z0UWJZcJtFGdK9vXRvQhQUA4B2ZLmn4+++/XbA7bdo0O3z4sHXp0sWefPJJ14fXP7XwoUOH7Oyzz7Z4R0kDCkKwO2jaYgt/8yf8//+f7dOMoBcAUPBqeAsSAl54mcoW2j78WUhmNzzoTSqTaPPuOtcKF/KHwAAAFIAaXgDesHDDrnSDXdEnYK3XdgAAeEGmAt6uXbvaggULjrnd/v377eGHH7bx48fnxNgA5IJt+w/l6HYAAHjipLV//OMfruWY0sbdu3e3Fi1aWOXKlS0xMdF2795tq1atsnnz5tnMmTPdRBRjx47N/ZEDyJKKpRJzdDsAADwR8F599dXWp08fe/PNN2369On2/PPPu3oJSUhIsPr167uT2L777js79dRTc3vMALKhVY1yrhvDlr2H0py0FlzDq+0AAPCCLJ+0poD3r7/+cn14ixYtal7CSWsoKF0aJPgXAF0aAADxIk9OWtMdJCUleS7YBQoCBbMKapXJDabrBLsAgAI78QQAb1FQ26l+kuvGoBPUVLOrMgZakQEAvIaAFyjAFNy2qfW/6cEBAPAq+vACAADA0wh4AQAA4GlZLmlYtGiRrV692v2stmTNmjXLyXEBAAAAsQl4t23bZpdddpnNnTvXypYt65bt2bPHzjnnHHv99dftxBNPzJmRAQAAALEoabjpppvcFMI//PCD7dq1y11WrlzpeqHdfPPNOTEmAAAAIHYTT6j/7uzZs61ly5YhyxcuXGidO3d22d54x8QTAAAABXjiidTU1IiTTWiZ1gEAAAD5SdQB77nnnmu33HKLbdq0KbDsjz/+sMGDB1uHDh1yenwAAABA3ga8zzzzjEshV69e3WrVquUuNWrUcMuefvrp7I0GAAAAiHWXhqpVq9rixYtdHe+aNWvcslNPPdU6duyY02MDAAAA8v6ktYKAk9YAAAC8E69lKsP71FNP2bXXXmuJiYnu54zQmgwAAABxl+FVje73339v5cuXdz+nu7OEBPv555+jHsT48eNt7NixtmXLFmvcuLGrBW7VqlXEbV966SUbMGBAyLLixYvboUOHAtf1kEaMGGETJ050bdLOPPNMe/bZZ61OnTqZGg8ZXgAAgAKW4d2wYUPEn3PC9OnTbciQITZhwgRr3bq1PfHEE9alSxdbu3atVaxYMeJt9KC0PjjQDvbII4+4TPSUKVNcgD5s2DC3z1WrVrksNQAAAAqOqLs0jBo1yv788880y//66y+3Llrjxo2zgQMHuqxt/fr1XeBbokQJmzRpUrq3UYCblJQUuFSqVCkku6ug+d5777WePXtao0aNbOrUqa6N2jvvvBNxf4cPH3afEoIvAAAAKKAB78iRI+3AgQNplisI1rpoHDlyxBYtWhTS4aFQoULu+vz589O9ne6/WrVqrmOEglpNcxycgVZpRPA+le5W9ji9fY4ZM8Zt479ovwAAACigAa8yqOElBLJs2TIrV65cVPvasWOHpaSkhGRoRdcVtEZSt25dl/199913bdq0aW52tzPOOMN+//13t95/u2j2OXToUFf/4b/89ttvUT0OAAAAeKAP7wknnOACXV1OOeWUkKBXQauyrtdff73ltjZt2riLn4Jd9QF+7rnnbPTo0Vnap0560wUAAAAFOOBVXayyu1dddZUrXdBX/37FihVzM68FB6KZUaFCBStcuLBt3bo1ZLmuqzY3M4oWLWpNmza1devWuev+22kfycnJIfts0qRJVOMDAABAAQp4+/Xr5/5X1wNlVRVoZpcC5ebNm9ucOXOsV69ebplKFHT9xhtvzNQ+lF1esWKFnXfeeYHxKejVPvwBrk5C+/bbb23QoEHZHjMAAAA8PrVwu3btAj+r961OPAsWbd9atSRTMN2iRQvXe1eZ5IMHDwZ67fbt29eqVKniTiwTdYI4/fTTrXbt2q7Hrvr3/vrrr3bNNde49Sq1uPXWW+3+++93fXf9bckqV64cCKoBAABQcEQd8Kobw5133mlvvPGG7dy5M2LGNRq9e/e27du32/Dhw91JZcrKzpo1K3DS2caNG13nBr/du3e7NmbaVnXFyhB/8803rqWZn8anoFmzwykobtu2rdsnPXgBAAAKnkzNtBbshhtusM8//9ydIHbllVe6WdL++OMPd9LYQw89ZFdccYXFO2ZaAwAAKGAzrQV7//333UQO7du3d2UHZ511lisvUF/cV155xRMBLwAAAApwH95du3ZZzZo13c+KpnVdVDbw5Zdf5vwIAQAAgLwMeBXsajYzqVevnqvl9Wd+y5Ytm52xAAAAALEPeFXGoFnV5O6773Y1vDoZbPDgwXbHHXfk/AgBAACAvDxpLZxagi1atMjV8TZq1Mi8gJPWAAAAvBOvRZXhPXr0qHXo0MF++umnwDKdrHbRRRd5JtgFAACAt0QV8Gp2teXLl+feaAAAAIBY1/D26dPHXnzxxZweBwAAAJArou7D+/fff9ukSZNs9uzZbpazkiVLhqwfN25cTo4PAAAAyNuAd+XKldasWTP3848//hiyLiEhIXujAQAAAGId8GpaYQAAAMCzNbwAAABAPCHgBQAAgKcR8AIAAMDTCHgBAADgaQS8AAAA8LRMdWl47733Mr3DHj16ZGc8AAAAQN4HvL169UrTb9fn84Vc90tJScnJ8QEAAAC5X9KQmpoauHzyySfWpEkT++ijj2zPnj3uMnPmTDcZxaxZs7I3GgAAACDWE0/ceuutNmHCBGvbtm1gWZcuXaxEiRJ27bXX2urVq3N6jAAAAEDenbS2fv16K1u2bJrlZcqUsV9++SXrIwEAAADyQ8DbsmVLGzJkiG3dujWwTD/fcccd1qpVq5weHwAAAJC3Ae+kSZNs8+bNdvLJJ1vt2rXdRT//8ccf9uKLL2ZvNAAAAECsa3gV4C5fvtw+/fRTW7NmjVt26qmnWseOHUO6NQAAAAD5QYIvuL9YlA4dOmTFixf3XKC7b98+V5O8d+9eK126dKyHAwAAgGzEa1GXNKg12ejRo61KlSp2/PHH24YNG9zyYcOGUdIAADkgJdVn89fvtHeX/uH+13UAQB6WNNx///02ZcoUe+SRR2zgwIGB5Q0aNLAnnnjCrr766mwMBwAKtlkrN9vI91fZ5r2HAsuSyyTaiO71rWuD5JiODQDiVdQZ3qlTp9rzzz9vV1xxhRUuXDiwvHHjxoGaXgBA1oLdQdMWhwS7smXvIbdc6wEAeRDwqhuDTlyLVOpw9OjRLAwBAKCyBWV2IxUv+JdpPeUNAJAHAW/9+vXtq6++SrP8rbfesqZNm2ZhCACAhRt2pcnsBlOYq/XaDgCQyzW8w4cPt379+rlMr7K6M2bMsLVr17pShw8++CDa3QEAzGzb/kM5uh0AIBsZ3p49e9r7779vs2fPtpIlS7oAePXq1W5Zp06dot0dAMDMKpZKzNHtAADZyPDKWWed5SaeAADkjFY1yrluDDpBLVKVrrqdJ5VJdNsBAPIg4JUjR47Ytm3bXFlDME0zDACITuFCCa71mLoxKLgNDnr9U/tovbYDAORyScNPP/3kMrzHHXecVatWzWrUqOEu1atXd/8DALJGfXaf7dPMZXKD6bqW04cXAPIow9u/f38rUqSIO0EtOTnZc9MKA0AsKajtVD/JdWPQCWqq2VUZA5ldAMjDgHfp0qW2aNEiq1evXjbuFgCQHgW3bWqVj/UwAKBg9+HdsWNH7owGAAAAiHXA+/DDD9udd95pc+fOtZ07d9q+fftCLgAAAEB+kuDz+aKap7JQof/FyOG1u9qNlqWkpFi8U+BepkwZ27t3r5UuXTrWwwEAAEA24rWoa3g///zzaG8CAAAAxEzUAW+7du1yZyQAAOSilFQf3S+AAipTAe/y5cutQYMGrpxBP2ekUaNGOTU2AAByxKyVm23k+6ts895DgWWa2U6TedDfGPC+TNXwKtDdsmWLVaxY0f2sWt1IN6OGFwCQH4NdzWAX/lfLn9tlUg8gPuV4De+GDRvsxBNPDPwMAEC8lDEosxsps+P7/0Gv1muyD8obAO/KVMCrKYQj/QwAQH6mmt3gMoZIQa/Wazsm+wC8K+qT1vxWrVplGzdutCNHjoQs79GjR06MCwCAbNMJajm5HYACEvD+/PPPduGFF9qKFStCann9fXm9UMMLAPAGdWPIye0AFJCZ1m655RarUaOGbdu2zUqUKGE//PCDffnll9aiRQs3+xoAAPmFWo+pG0N61blarvXaDoB3RR3wzp8/30aNGmUVKlRwHRt0adu2rY0ZM8Zuvvnm3BklAABZoBPR1HpMwoNe/3Wt54Q1wNuiDnhVslCqVCn3s4LeTZs2BU5mW7t2bc6PEACAbFDLMbUeSyoTWrag67QkAwqGqGt4NQHFsmXLXFlD69at7ZFHHrFixYrZ888/bzVr1sydUQIAkA0KatV6jJnWgIIp6oD33nvvtYMHD7qfVdpwwQUX2FlnnWXly5e36dOn58YYAQDINgW3tB4DCqZMzbR2LLt27bITTjgh0Kkh3jHTGgAAQAGbae1YypXj7FYAAADkT5kKeC+66KJM73DGjBnZGQ8AAACQ9wGv0sUAAACAZwPeyZMn5/5IAAAAgFyQ5RpezbTm77tbt25dq1ixYk6OCwAAAIjNxBM6I+7KK6+0KlWqWLt27dxFP/fp08edJQcAAADEdcA7cOBA+/bbb+2DDz6wPXv2uIt+/v777+26667LnVECAAAAedWHt2TJkvbxxx9b27ZtQ5Z/9dVX1rVr18CkFPGMPrwAAADeideizvBqRrVIXRu0TJNPAAAAAPlJoaxMLTxkyBDbsmVLYJl+vuOOO2zYsGE5PT4AAAAgb0samjZtauvWrbPDhw/bySef7JZt3LjRihcvbnXq1AnZdvHixRaPKGkAAAAowFML9+rVy3La+PHjbezYsS5T3LhxY3v66aetVatWx7zd66+/bpdffrn17NnT3nnnncDy/v3725QpU0K27dKli82aNSvHxw4AAID8LeqAd8SIETk6gOnTp7sSiQkTJljr1q3tiSeecMGpevxm1Nv3l19+sdtvv93OOuusiOt1Al3whBnKQAMAAKDgibqG9/PPP0933XPPPRf1AMaNG+danQ0YMMDq16/vAt8SJUrYpEmT0r1NSkqKXXHFFTZy5EirWbNmxG0U4CYlJQUunFAHAABQMEUd8CpzqhPUjh49Gli2Y8cO6969u919991R7evIkSO2aNEi69ix4/8NqFAhd33+/Pnp3m7UqFEu+3v11Venu83cuXPdNpoFbtCgQbZz5850t1U9supAgi8AAAAowBnet99+21q2bGmrVq2yDz/80Bo0aOCCxKVLl0a1LwXKytZWqlQpZLmuB3eBCDZv3jx78cUXbeLEiRkG5VOnTrU5c+bYww8/bF988YV169bN3VckY8aMcUXP/kvVqlWjehwAAADwUA3vGWec4QLb66+/3po1a2apqak2evRou/POOy0hIcFy0/79+920xgp2K1SokO52l112WeDnhg0bWqNGjaxWrVou69uhQ4c02w8dOtTVEfspeCfoBQAAKKABr/z4449uKuGTTjrJNm3a5E4w+/PPP90sbNFQ0Fq4cGHbunVryHJdV91tuPXr17uT1VQ+4aeA2z2QIkXcOBTYhlOdr+5L7dQiBbyq9+WkNgAAAG+KuqThoYcesjZt2linTp1s5cqVtnDhQluyZInLomZUdxtJsWLFrHnz5q70IDiA1XXdR7h69erZihUrXIbZf+nRo4edc8457uf0srK///67q+FNTk6O9uECAACgoGV4n3zySdfzVjWxovpdBb3//ve/rX379u4EsGiolKBfv37WokUL13tXbckOHjzoujZI3759rUqVKq7ONjEx0d1fsLJlywbGIQcOHHDdGy6++GKXJVZWWOUWtWvXdu3OAAAAULBEHfAqwxpeP1u0aFE3ccQFF1wQ9QB69+5t27dvt+HDh7sT1Zo0aeImiPCfyKZZ3NS5IbNUIrF8+XI38cSePXuscuXK1rlzZ1dnTNkCAABAwRP11MKiQPKtt95y2VO1KCtXrpybRlhBqrKx8Y6phQEAAArw1MLKnqpPru5AJ5Bp0ggFvDNmzHDZWLUDAwAAAOL2pLXBgwdb//797aeffnI1tX7nnXeeffnllzk9PgAAACBbos7wqh3Z888/n2a5ShnSmywCAAAAiJsMr078ijT1rnrznnjiiTk1LgAAACA2Aa/63o4aNcqOHj3qrmt2NdXu3nXXXa4VGAAAABDXAe9jjz3met1WrFjR/vrrL2vXrp3rcVuqVCl74IEHcmeUAAAAQF7V8Ko7w6effmpff/21LVu2zAW/zZo1c50bAAAAkPNSUn22cMMu27b/kFUslWitapSzwoUSYj0sb/fh9Tr68AIAgPxi1srNNvL9VbZ576HAsuQyiTaie33r2iDZCqp9UcRrUZc0AAAAIO+C3UHTFocEu7Jl7yG3XOtxbAS8AAAA+bSMQZndSF/F+5dpvbZDxgh4AQAA8iHV7IZndoMpzNV6bYeMEfACAADkQzpBLSe3K8iyFPCuX7/e7r33Xrv88stt27ZtbtlHH31kP/zwQ06PDwAAoEBSN4ac3K4gizrg/eKLL6xhw4b27bff2owZM1xbMlGLshEjRuTGGAEAAAoctR5TN4b0mo9pudZrO+RwwHv33Xfb/fff73rxFitWLLD83HPPtQULFkS7OwAAAESgPrtqPSbhQa//utbTjzcXAt4VK1bYhRdemGa5Zl7bsWNHtLsDAABAOtRn99k+zSypTGjZgq5reUHuw5urM62VLVvWNm/ebDVq1AhZvmTJEqtSpUq0uwMAAEAGFNR2qp/ETGt5GfBedtlldtddd9mbb75pCQkJlpqa6qYZvv32261v377ZGQsAAAAiUHDbplb5WA+j4JQ0PPjgg1avXj2rWrWqO2Gtfv36dvbZZ9sZZ5zhOjcAAAAA+UmCz+fL0vQcGzdutJUrV7qgt2nTplanTh0riHMzAwAAIH/Ha1GXNMybN8/atm1rJ598srsAAAAAnippUPsxnbD273//21atWpU7owIAAABiFfBu2rTJbrvtNjcBRYMGDaxJkyY2duxY+/3333NqTAAAAEDsa3hlw4YN9uqrr9prr71ma9ascSevffbZZxbvqOEFAADwTryWrYBXUlJS7KOPPrJhw4bZ8uXL3fV4R8ALAADgnXgt6pIGP/Xe/de//mXJycn2z3/+05U3fPjhh1ndHQAAAJArou7SMHToUHv99dddLW+nTp3sySeftJ49e1qJEiVyZ4QAAABAXga8X375pd1xxx126aWXWoUKFbJz3wAAAED+C3hVygAAAAB4KuB97733rFu3bla0aFH3c0Z69OiRU2MDAAAAsi1TXRoKFSpkW7ZssYoVK7qf091ZQgJdGgAAABB/UwunpqZG/BkAAADI76JuSzZ16lQ7fPhwmuVHjhxx6wAAAID8JOqJJwoXLmybN2925Q3Bdu7c6ZZR0gAAAIC4nnhC8bFqdcP9/vvv7k4BAACAuGxL1rRpUxfo6tKhQwcrUuT/bqqs7oYNG6xr1665NU4AAAAgdwPeXr16uf+XLl1qXbp0seOPPz6wrlixYla9enW7+OKLszYKAAAAINYB74gRI9z/Cmx79+5tiYmJuTUmAAAAIHYzrfXr1y/n7h0AAADIbwGv6nUff/xxe+ONN2zjxo2uHVmwXbt25eT4AAAAgGyJukvDyJEjbdy4ca6sQW0ghgwZYhdddJGbge2+++7L3mgAAACAWAe8r7zyik2cONFuu+0216nh8ssvtxdeeMGGDx9uCxYsyOnxAQAAAHkb8G7ZssUaNmzoflanBmV55YILLrAPP/wwe6MBAAAAYh3wnnTSSW6mNalVq5Z98skn7ufvvvvOihcvntPjAwAAAPI24L3wwgttzpw57uebbrrJhg0bZnXq1LG+ffvaVVddlb3RAAAAADkswae5grNh/vz57qKgt3v37lbQ5mYGAABA/o7Xom5LFq5NmzbuAgAAAORHmQp433vvvUzvsEePHtkZDwAAAJD3AW+vXr0ytbOEhAQ3MQUAAAAQVwFvampq7o8EAAAAyA9dGgAAAIB4EvVJa6NGjcpwvWZcAwAAAOI24H377bdDrh89etQ2bNjgphnWRBQEvAAAAIjrgHfJkiUR+6D179/fTUoBAAAAeGriCb8VK1a4iSd++eUXi3dMPAGgoEtJ9dnCDbts2/5DVrFUorWqUc4KF0qI9bAAIDYTT/jpznQBAMS3WSs328j3V9nmvYcCy5LLJNqI7vWta4PkmI4NALIi6oD3qaeeCrmuBPHmzZvt5Zdftm7dumVpEACA/BPsDpq22MK/+tuy95Bb/myfZgS9ALwf8D7++OMh1wsVKmQnnnii9evXz4YOHZqTYwMA5HEZgzK7kerctEwFDVrfqX4S5Q0AvB3wqiMDAMB7VLMbXMYQKejVem3Xplb5PB0bAGQHE08AABydoJaT2wFA3GZ4Dx06ZE8//bR9/vnntm3btjTTDi9evDgnxwcAyCPqxpCT2wFA3Aa8V199tX3yySd2ySWXWKtWrSwhgTouAPACtR5TNwadoBapjle/7ZPK/K9FGQB4OuD94IMPbObMmXbmmWfmzogAADGhE9HUekzdGBTcBge9/tSG1nPCGgDP1/BWqVLFSpUqlTujAQDElFqOqfWYMrnBdJ2WZAAKzExrH330kevFO2HCBKtWrZp5ETOtASjomGkNQIGeaa1FixbuxLWaNWtaiRIlrGjRoiHrd+3aFf2IAQD5ioJbWo8BKLAlDZdffrn98ccf9uCDD7puDZqIIviSFePHj7fq1atbYmKitW7d2hYuXJip273++uvupLlevXqFLFfSevjw4ZacnGzHHXecdezY0X766acsjQ0AAADxLeoM7zfffGPz58+3xo0b58gApk+fbkOGDHElEgp2n3jiCevSpYutXbvWKlasmO7tfvnlF7v99tvtrLPOSrPukUcecWUXU6ZMsRo1atiwYcPcPletWuWCagAAABQcUWd469WrZ3/99VeODWDcuHE2cOBAGzBggNWvX98FviqVmDRpUrq3SUlJsSuuuMJGjhzpSivCs7sKmu+9917r2bOnNWrUyKZOnWqbNm2yd955J8fGDQAAAI8GvA899JDddtttNnfuXNu5c6crGA6+ROPIkSO2aNEiV3IQGFChQu66ssjpGTVqlMv+qidwpKmPt2zZErJPFTQre5zePg8fPpytxwEAAAAPlTR07drV/d+hQ4c0mVXV0yr7mlk7duxw21eqVClkua6vWbMm4m3mzZtnL774oi1dujTiegW7/n2E79O/LtyYMWNcthgAAADeE3XAqymFY2X//v125ZVX2sSJE61ChQo5tt+hQ4e6OmI/ZXirVq2aY/sHAABAHAW87dq1y7E7V9BauHBh27p1a8hyXU9KSkqz/fr1693Jat27dw8sS01Ndf8XKVLEnejmv532oS4Nwfts0qRJxHEUL17cXQAAAOA9UQe8X375ZYbrzz777Ezvq1ixYta8eXObM2dOoLWYAlhdv/HGGyOeMLdixYqQZTo5TZnfJ5980mVl1RdYQa/24Q9wlbH99ttvbdCgQZkeGwAAAApowNu+ffs0y1S76xdNDa+olKBfv35uQotWrVq5DgsHDx50XRukb9++bjpj1dmqpViDBg1Cbl+2bFn3f/DyW2+91e6//36rU6dOoC1Z5cqV0/TrBQAAgPdFHfDu3r075PrRo0dtyZIlLqh84IEHoh5A7969bfv27W6iCJ1UpqzsrFmzAiedbdy40XVuiMadd97pguZrr73W9uzZY23btnX7pAcvAABAwZPgU3uFHPDFF1+4bK3ajBWkuZkBAACQv+O1qPvwpkcZWZ00BgAAAMR1ScPy5ctDritBvHnzZjchRXpdEAAAAIC4CXgV1OoktfBKiNNPPz3D6YABAACAuAh4NXVvMJ1QduKJJ3JCGAAAALwR8FarVi13RgIAAADkgkyftPbZZ59Z/fr13Rlx4XR23GmnnWZfffVVTo8PAAAAyJuAVxNCDBw4MGLbB7WEuO6662zcuHHZGw0AAAAQq4B32bJl1rVr13TXd+7c2RM9eAEAAFBAA96tW7da0aJF011fpEgRN2MaAAAAEJcBb5UqVWzlypUZ9udNTk7OqXEBAAAAeRvwnnfeeTZs2DA7dOhQmnV//fWXjRgxwi644IKcGRUAAACQQxJ84TNIZFDS0KxZMytcuLDdeOONVrduXbd8zZo1Nn78eEtJSbHFixe7KYYL0tzMAAAAyN/xWqb78CqQ/eabb2zQoEE2dOjQwExrmnWtS5cuLuj1QrALAACAAjzxhCadmDlzpu3evdvWrVvngt46derYCSeckHsjBAAAAPJypjVRgNuyZcvs3C8AAACQv05aAwAAAOIRAS8AAAA8jYAXAAAAnkbACwAAAE8j4AUAAICnEfACAADA0wh4AQAA4GkEvAAAAPA0Al4AAAB4GgEvAAAAPI2AFwAAAJ5GwAsAAABPI+AFAACApxHwAgAAwNMIeAEAAOBpBLwAAADwNAJeAAAAeBoBLwAAADyNgBcAAACeRsALAAAATyPgBQAAgKcR8AIAAMDTCHgBAADgaQS8AAAA8DQCXgAAAHgaAS8AAAA8jYAXAAAAnkbACwAAAE8j4AUAAICnEfACAADA0wh4AQAA4GkEvAAAAPC0IrEeAAAAyDspqT5buGGXbdt/yCqWSrRWNcpZ4UIJsR4WkKsIeAEAKCBmrdxsI99fZZv3HgosSy6TaCO617euDZJjOjYgN1HSAABAAQl2B01bHBLsypa9h9xyrQe8ioAXAIACUMagzK4vwjr/Mq3XdoAXEfACAOBxqtkNz+wGU5ir9doO8CICXgAAPE4nqOXkdkC8IeAFAMDj1I0hJ7cD4g0BLwAAHqfWY+rGkF7zMS3Xem0HeBEBLwAAHqc+u2o9JuFBr/+61tOPF15FwAsAQAGgPrvP9mlmSWVCyxZ0XcvpwwsvY+IJAAAKCAW1neonMdMaChwCXgAAChAFt21qlY/1MIA8RUkDAAAAPI2AFwAAAJ5GwAsAAABPI+AFAACApxHwAgAAwNMIeAEAAOBpBLwAAADwtHwR8I4fP96qV69uiYmJ1rp1a1u4cGG6286YMcNatGhhZcuWtZIlS1qTJk3s5ZdfDtmmf//+lpCQEHLp2rVrHjwSAAAA5Dcxn3hi+vTpNmTIEJswYYILdp944gnr0qWLrV271ipWrJhm+3Llytk999xj9erVs2LFitkHH3xgAwYMcNvqdn4KcCdPnhy4Xrx48Tx7TAAAAMg/Enw+ny+WA1CQ27JlS3vmmWfc9dTUVKtatarddNNNdvfdd2dqH82aNbPzzz/fRo8eHcjw7tmzx955550sjWnfvn1WpkwZ27t3r5UuXTpL+wAAAEDuiSZei2lJw5EjR2zRokXWsWPH/xtQoULu+vz58495e8Xqc+bMcdngs88+O2Td3LlzXda3bt26NmjQINu5c2e6+zl8+LA7aMEXAAAAeENMSxp27NhhKSkpVqlSpZDlur5mzZp0b6dIvkqVKi5QLVy4sP3nP/+xTp06hZQzXHTRRVajRg1bv369/fvf/7Zu3bq5IFrbhxszZoyNHDkyhx8dAAAA8oOY1/BmRalSpWzp0qV24MABl+FVDXDNmjWtffv2bv1ll10W2LZhw4bWqFEjq1Wrlsv6dujQIc3+hg4d6vbhpwyvyioAAAAQ/2Ia8FaoUMFlXLdu3RqyXNeTkpLSvZ3KHmrXru1+VpeG1atXuyytP+ANp2BY97Vu3bqIAa9OaOOkNgAAAG+KaQ2vuiw0b97cZWn9dNKarrdp0ybT+9FtVN6Qnt9//93V8CYnJ2d7zAAAAIgvMS9pUClBv379XG/dVq1aubZkBw8edK3GpG/fvq5eVxlc0f/aViUKCnJnzpzp+vA+++yzbr3KHFSPe/HFF7sssWp477zzTpcRDm5bBgAAgIIh5gFv7969bfv27TZ8+HDbsmWLK1GYNWtW4ES2jRs3uhIGPwXD//rXv1zW9rjjjnP9eKdNm+b2IyqRWL58uU2ZMsW1JqtcubJ17tzZtSyjbAEAAKDgiXkf3vyIPrwAAAD5W9z04QUAAAByGwEvAAAAPI2AFwAAAJ5GwAsAAABPI+AFAACApxHwAgAAwNMIeAEAAOBpMZ94AgCArEpJ9dnCDbts2/5DVrFUorWqUc4KF0qI9bAA5DMEvACAuDRr5WYb+f4q27z3UGBZcplEG9G9vnVtkBzTsQHIXyhpAADEZbA7aNrikGBXtuw95JZrPQD4EfACAOKujEGZXV+Edf5lWq/tAOQNvd/mr99p7y79w/2f395/lDQAAOKKanbDM7vB9GdW67Vdm1rl83RsQEE0Kw7Ki8jwAgDiik5Qy8ntAHi/vIiAFwAQV9SNISe3A+D98iICXgBAXFHrMX1dml7zMS3Xem0HIPdEU14UawS8AIC4oj67qg2U8KDXf13r6ccL5K5tcVReRMALAIg7OhHm2T7NLKlMaNmCrmt5fjlRBvCyinFUXkSXBgBAXFJQ26l+EjOtATEuL9qy91DEOt6E//8hND+UFxHwAgDiloJbWo8BsS0vGjRtsQtuffm4vIiSBgAAAHi6vIgMLwAAADxdXkTACwAAAE+XF1HSAAAAAE8j4AUAAICnUdIAAADyJU1Jm5/rQhE/CHgBAEC+M2vlZhv5/qqQqWvV81VtrvLLmf+IH5Q0AACAfBfsqrdrcLArmuBAy7UeiAYBLwAAyFdlDMrsRpq5y79M67UdkFkEvAAAIN9QzW54ZjeYwlyt13ZAZhHwAgCAfEMnqOXkdoAQ8AIAgHxD3RhycjtACHgBAEC+odZj6saQXvMxLdd6bQdkFgEvAADIN9RnV63HJDzo9V/XevrxIhoEvAAAIF9Rn91n+zSzpDKhZQu6ruX04UW0mHgCAADkOwpqO9VPYqY15AgCXgAAkC8puG1Tq3yshwEPoKQBAAAAnkbACwAAAE8j4AUAAICnEfACAADA0wh4AQAA4GkEvAAAAPA0Al4AAAB4GgEvAAAAPI2AFwAAAJ5GwAsAAABPI+AFAACApxHwAgAAwNMIeAEAAOBpRWI9gPzI5/O5//ft2xfroQAAACACf5zmj9syQsAbwf79+93/VatWjfVQAAAAcIy4rUyZMhltYgm+zITFBUxqaqpt2rTJSpUqZQkJCbEeTr76JKUPAb/99puVLl061sOJOxy/7OH4ZR3HLns4ftnD8csejl/6FMIq2K1cubIVKpRxlS4Z3gh00E466aRYDyPf0huON13Wcfyyh+OXdRy77OH4ZQ/HL3s4fpEdK7Prx0lrAAAA8DQCXgAAAHgaAS8yrXjx4jZixAj3P6LH8csejl/Wceyyh+OXPRy/7OH45QxOWgMAAICnkeEFAACApxHwAgAAwNMIeAEAAOBpBLwAAADwNAJeHFP16tXdjHPhlxtuuCHWQ8v3UlJSbNiwYVajRg077rjjrFatWjZ69OhMzfuN/9EsOrfeeqtVq1bNHcMzzjjDvvvuu1gPK1/68ssvrXv37m7WIb1H33nnnZD1et0NHz7ckpOT3bHs2LGj/fTTTzEbb7wdvxkzZljnzp2tfPnybv3SpUtjNtZ4O35Hjx61u+66yxo2bGglS5Z02/Tt29fNaorMvf7uu+8+q1evnjt+J5xwgnv/fvvttzEbb7wh4MUxKbjYvHlz4PLpp5+65f/4xz9iPbR87+GHH7Znn33WnnnmGVu9erW7/sgjj9jTTz8d66HFjWuuuca95l5++WVbsWKFCzj0i/6PP/6I9dDynYMHD1rjxo1t/PjxEdfrtffUU0/ZhAkT3B9K/eHs0qWLHTp0KM/HGo/HT+vbtm3r3seI7vj9+eeftnjxYpcA0P/68LB27Vrr0aNHTMYaj6+/U045xf0t0e/BefPmuWSUfh9u3749z8cal9SWDIjGLbfc4qtVq5YvNTU11kPJ984//3zfVVddFbLsoosu8l1xxRUxG1M8+fPPP32FCxf2ffDBByHLmzVr5rvnnntiNq54oF/vb7/9duC63q9JSUm+sWPHBpbt2bPHV7x4cd9rr70Wo1HGz/ELtmHDBrd+yZIleT4uLxw/v4ULF7rtfv311zwbl5eO3969e912s2fPzrNxxTMyvIjKkSNHbNq0aXbVVVe5r1yQMX39PmfOHPvxxx/d9WXLlrlP5t26dYv10OLC33//7cpCEhMTQ5br63gdR2Tehg0bbMuWLS47HjwHfevWrW3+/PkxHRsKpr1797q/I2XLlo31UOLyb/Hzzz/v3sPKCuPYimRiGyBANUV79uyx/v37x3ooceHuu++2ffv2ubqrwoULu+DtgQcesCuuuCLWQ4sLpUqVsjZt2ri651NPPdUqVapkr732mgvQateuHevhxRUFu6JjGEzX/euAvKIyGtX0Xn755Va6dOlYDydufPDBB3bZZZe5EhHV4qvcq0KFCrEeVlwgw4uovPjiiy47qaJ6HNsbb7xhr7zyir366quubm3KlCn26KOPuv+ROard1Td8VapUcVNrqgZVfyQLFeLXFxCPdALbpZde6t7XOscBmXfOOee4kyW/+eYb69q1qzuO27Zti/Ww4gJ/MZBpv/76q82ePdudRITMueOOO1yWV5/IdXbylVdeaYMHD7YxY8bEemhxQ50tvvjiCztw4ID99ttvtnDhQvcHs2bNmrEeWlxJSkpy/2/dujVkua771wF5Fezq74myk2R3o6MTTfXt1umnn+4SUEWKFHH/49gIeJFpkydPtooVK9r5558f66HEDX3tFJ6JVGlDampqzMYUz7/o9RXe7t277eOPP7aePXvGekhxRa3xFNiqptxP5Tbq1qCyESCvgl21wlPyRO3dkD36W3L48OFYDyMuUMOLTL+pFPD269fPfaJE5qinomp2Tz75ZDvttNNsyZIlNm7cOHfSHzJHwa2++qxbt66tW7fOZc1VEz1gwIBYDy3fURZcxyj4RDV9/VmuXDn3GlQ/4/vvv9/q1KnjAmC1iFJ5Uq9evWI67ng5frt27bKNGzcGeseqrZbogwRZ8oyPnz6sXnLJJa60S3WoOp/BXzuu9cWKFbOCLqPjpw8H+luiNm46ljt27HDty9SekRahmRTrNhGIDx9//LFrf7J27dpYDyWu7Nu3z7VxO/nkk32JiYm+mjVrunZahw8fjvXQ4sb06dPdcStWrJhrq3XDDTe4dlpI6/PPP3fv0/BLv379Aq3Jhg0b5qtUqZJrR9ahQwfe01Ecv8mTJ0dcP2LEiFgPPd8fP38rt0gX3Q4ZH7+//vrLd+GFF/oqV67sfhcmJyf7evTo4Vq7IXMS9E9mg2MAAAAg3lDDCwAAAE8j4AUAAICnEfACAADA0wh4AQAA4GkEvAAAAPA0Al4AAAB4GgEvAAAAPI2AFwAAAJ5GwAsgz7Vv395Nc5sbzj77bHv11Vctv3jppZesbNmylp+88847Vrt2bStcuHCuPQ8F3apVq+ykk06ygwcPxnooAAh4AXjJe++9Z1u3brXLLrsssKx69eqWkJBgCxYsCNlWgZ4C74Louuuus0suucR+++03Gz16tBUUv/zyi3stLF26NNfvq379+nb66afbuHHjcv2+ABwbAS8Az3jqqadswIABVqhQ6K+2xMREu+uuu8xLjh49mqXbHThwwLZt22ZdunSxypUrW6lSpSyvHDlyxArS8ddr8dlnn7W///47T8YEIH0EvABibvfu3da3b1874YQTrESJEtatWzf76aefQraZOHGiVa1a1a2/8MILXeYsuFRg+/bt9tlnn1n37t3T7P/aa691Gd6ZM2dGVWbRq1cv69+/f0i2+P7773djPf74461atWouq6z77tmzp1vWqFEj+/777yOWEdSpU8cF3wo2lV0N9u6771qzZs3c+po1a9rIkSNDAiVlJhU89ejRw0qWLGkPPPBA1Mdy7ty5gQD33HPPdfvUskj896fbH3fccW5Mb731Vsg2+hBxyimnuPvR+mHDhoUEgvfdd581adLEXnjhBatRo4Z7bDJr1ixr27ate/7Kly9vF1xwga1fvz5NJvaNN96ws846y91/y5Yt7ccff7TvvvvOWrRo4Y61xqZjH0z3deqpp7r7qlevnv3nP/8JrNMYpGnTpm7/wRn+jG7nH8/06dOtXbt2bptXXnnFfv31V/d607HWc3LaaaeFvMY6depku3btsi+++CLiMQaQh3wAkMfatWvnu+WWWwLXe/To4Tv11FN9X375pW/p0qW+Ll26+GrXru07cuSIWz9v3jxfoUKFfGPHjvWtXbvWN378eF+5cuV8ZcqUCexjxowZvpIlS/pSUlJC7qtatWq+xx9/3HfzzTf7GjVqFFiv+9c40huT9OzZ09evX7+Qfel+J0yY4Pvxxx99gwYN8pUuXdrXtWtX3xtvvOHG1qtXL/dYUlNT3W0mT57sK1q0qK9Fixa+b775xvf999/7WrVq5TvjjDMC+9Xj1n5eeukl3/r1632ffPKJr3r16r777rsvsI1+XVesWNE3adIkt82vv/4a8dhmdCwPHz7sxqh9/fe///Vt3rzZLYtE25QvX943ceJEd5t7773XV7hwYd+qVasC24wePdr39ddf+zZs2OB77733fJUqVfI9/PDDgfUjRoxwz4mOz+LFi33Lli1zy9966y13/z/99JNvyZIlvu7du/saNmwYeG60P91/vXr1fLNmzXL3efrpp/uaN2/ua9++vXs9aH96XNdff33g/qZNm+ZLTk52+/7555/d/3q+dFxl4cKFbr+zZ892j33nzp2Zup1/PHpO/Nts2rTJd/755/s6derkW758uXtO3n//fd8XX3wRchxbt27tjgOA2CLgBZDngoNLBY4KJhQ4+e3YscN33HHHuSBSevfu7YKLYFdccUVIwKugtmbNmmnuyx/wbtu2zVeqVCnf1KlTsxXw9unTJ3BdQZPGPmzYsMCy+fPnu2Va5w94dX3BggWBbVavXu2Wffvtt+56hw4dfA8++GDIfb/88ssuCPPT9rfeemuGxzUzx3L37t1um88//zzDfWmb4GDSH7wpyE+PPpAoKPVToKdgX8c+I9u3b3f3t2LFipAA84UXXghs89prr7llc+bMCSwbM2aMr27duoHrtWrV8r366qsh+1ZQ3qZNm5D9KsgOltnbPfHEEyHbKEgP/lASyYUXXujr379/htsAyH2UNACIqdWrV1uRIkWsdevWgWX6mrtu3bpunaxdu9ZatWoVcrvw63/99VfgK/NITjzxRLv99ttt+PDh2aolVcmCX6VKldz/DRs2TLNMdbJ+enz6St5PX5nr63z/41u2bJmNGjXKfU3vvwwcONA2b95sf/75Z+B2+io/u8cyGm3atElzPXg/+or/zDPPtKSkJDfme++91zZu3BhyG5V96NgHU4nF5Zdf7sogSpcu7UpFJPy2mTnW/uOsbggqi7j66qtDjqNKUILLJcJFc7vw43/zzTe77XQMRowYYcuXL0+zf5VjBD+HAGKjSIzuFwByVIUKFVz9akaGDBniajOD6zP9dKLb/xKbGZ+YVLRo0cDPqutMb1lqampUJ5KpZveiiy5Ksy44iFedaH4xf/58u+KKK9y4VZNcpkwZe/311+2xxx4L2S7SmFX3qkBYddk6cU7HqkGDBmk+iGTmWPuPs46haJ/BAb+o/Vp6orld+GO55ppr3GP/8MMP7ZNPPrExY8a4x3/TTTcFtlENb61atdK9fwB5gwwvgJjSiUI6Oevbb78NLNu5c6fL6qq1kyhDqZOVgoVf14lIW7ZsyTDoVeZOJ1bphK/9+/eHrFMWUhlVv5SUFFu5cqXlBD2+4BPZ9Nj27NnjHrvoZDUtU2/c8Et4x4nsHstohLdy03X/mL/55hsXtN5zzz0u86kT8nQS17H4x6NscIcOHdz+jvVBJTOU7VXw/PPPP6c5hv6T1YoVKxZ4bqO5XUZ0IuX1119vM2bMsNtuu80FzsH0GtJrE0BskeEFEFMKlNThQF/hP/fcc66LwN13321VqlRxy0UZM00ooc4Myg6qG8NHH30UyPqJggpleb/++mt31n961LHh8ccfd5NTBGf01LVAGWBl65SR030pKM0JykrqMahtmkoObrzxRtej1V+WoTILjfnkk092/XEV5KrMQcGSvjLPyWMZjTfffNMFs+qooK4ECxcutBdffDFwXypBUFZX5Ro6bm+//fYx96mOBiqzeP755y05OdntQ2PMCco2q8xA2eauXbva4cOH3QcNBdR6bitWrOhKDNQlQpNCKHuubY91u/Soq4c6RahThbb9/PPPAx8I/N0d/vjjD+vYsWOOPD4AWUeGF0DMTZ482Zo3b+6CPtWJqrRA7Z38X1+rRnLChAkuCG3cuLELWAYPHhzydb++flbfUwVmGdE+NdnCoUOHQpZfddVV1q9fP9fSS62nVF96zjnn5MjjU9sutfD65z//6R6LMs2qf/XT1+IffPCB+1pcwaOCYQXlyqDm9LGMhgJBBbSqpZ06daq99tprgUyx2qPpOVDwrtZjyvgqe34sCua1z0WLFrkyBu1j7NixlhNUYqD2YjoGqvXV86iZ7vyZWn3Y0IcOfRhQVtf/IeBYt0uPMsU33HCDC3IVKCvwDS6X0fHq3Llzlp5HADkrQWeu5fA+ASDXKYu5Zs0a++qrrwLLVNKgXqiLFy8myMgmZc+VsVUvYkRP9cjKguubBH3IARBbZHgBxIVHH33Ufc2/bt06e/rpp23KlCkuIxtM3QL0lXv42f5AXtNr8N///jfBLpBPkOEFEBcuvfRSNyuYTjZTuYFqYnWyEHIHGV4AXkLACwAAAE+jpAEAAACeRsALAAAATyPgBQAAgKcR8AIAAMDTCHgBAADgaQS8AAAA8DQCXgAAAHgaAS8AAADMy/4foc8/32nGN/QAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Datas_drawing = []\n",
    "for i, val in enumerate(Datas):\n",
    "    y = cumulative_explained_ratio(val, alpha=0.9)\n",
    "    x = np.log(len(val))\n",
    "    Datas_drawing.append((x, y[0]))\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(*zip(*Datas_drawing))\n",
    "plt.xlabel(\"log(Number of parameters)\")\n",
    "plt.ylabel(\"Cumulative explained ratio (90%)\")\n",
    "plt.title(\"Model Complexity vs. Curvature Concentration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746c40b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Rectangle.set() got an unexpected keyword argument 'num_bins'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m la\u001b[38;5;241m.\u001b[39mfit(train_loader)\n\u001b[0;32m      6\u001b[0m val \u001b[38;5;241m=\u001b[39m la\u001b[38;5;241m.\u001b[39mH\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m----> 7\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_bins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\doyoung_laplace\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:453\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[0;32m    448\u001b[0m     warn_deprecated(\n\u001b[0;32m    449\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    450\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    451\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only in \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    452\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\doyoung_laplace\\lib\\site-packages\\matplotlib\\pyplot.py:3478\u001b[0m, in \u001b[0;36mhist\u001b[1;34m(x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, data, **kwargs)\u001b[0m\n\u001b[0;32m   3453\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mhist)\n\u001b[0;32m   3454\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhist\u001b[39m(\n\u001b[0;32m   3455\u001b[0m     x: ArrayLike \u001b[38;5;241m|\u001b[39m Sequence[ArrayLike],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3476\u001b[0m     BarContainer \u001b[38;5;241m|\u001b[39m Polygon \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[BarContainer \u001b[38;5;241m|\u001b[39m Polygon],\n\u001b[0;32m   3477\u001b[0m ]:\n\u001b[1;32m-> 3478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mhist(\n\u001b[0;32m   3479\u001b[0m         x,\n\u001b[0;32m   3480\u001b[0m         bins\u001b[38;5;241m=\u001b[39mbins,\n\u001b[0;32m   3481\u001b[0m         \u001b[38;5;28mrange\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrange\u001b[39m,\n\u001b[0;32m   3482\u001b[0m         density\u001b[38;5;241m=\u001b[39mdensity,\n\u001b[0;32m   3483\u001b[0m         weights\u001b[38;5;241m=\u001b[39mweights,\n\u001b[0;32m   3484\u001b[0m         cumulative\u001b[38;5;241m=\u001b[39mcumulative,\n\u001b[0;32m   3485\u001b[0m         bottom\u001b[38;5;241m=\u001b[39mbottom,\n\u001b[0;32m   3486\u001b[0m         histtype\u001b[38;5;241m=\u001b[39mhisttype,\n\u001b[0;32m   3487\u001b[0m         align\u001b[38;5;241m=\u001b[39malign,\n\u001b[0;32m   3488\u001b[0m         orientation\u001b[38;5;241m=\u001b[39morientation,\n\u001b[0;32m   3489\u001b[0m         rwidth\u001b[38;5;241m=\u001b[39mrwidth,\n\u001b[0;32m   3490\u001b[0m         log\u001b[38;5;241m=\u001b[39mlog,\n\u001b[0;32m   3491\u001b[0m         color\u001b[38;5;241m=\u001b[39mcolor,\n\u001b[0;32m   3492\u001b[0m         label\u001b[38;5;241m=\u001b[39mlabel,\n\u001b[0;32m   3493\u001b[0m         stacked\u001b[38;5;241m=\u001b[39mstacked,\n\u001b[0;32m   3494\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m   3495\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3496\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\doyoung_laplace\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:453\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[0;32m    448\u001b[0m     warn_deprecated(\n\u001b[0;32m    449\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    450\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    451\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only in \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    452\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\doyoung_laplace\\lib\\site-packages\\matplotlib\\__init__.py:1524\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1521\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1523\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1524\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\n\u001b[0;32m   1525\u001b[0m             ax,\n\u001b[0;32m   1526\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(cbook\u001b[38;5;241m.\u001b[39msanitize_sequence, args),\n\u001b[0;32m   1527\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: cbook\u001b[38;5;241m.\u001b[39msanitize_sequence(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()})\n\u001b[0;32m   1529\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1530\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1531\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\doyoung_laplace\\lib\\site-packages\\matplotlib\\axes\\_axes.py:7316\u001b[0m, in \u001b[0;36mAxes.hist\u001b[1;34m(self, x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, **kwargs)\u001b[0m\n\u001b[0;32m   7308\u001b[0m p \u001b[38;5;241m=\u001b[39m patch[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   7309\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[0;32m   7310\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhatch\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mnext\u001b[39m(hatches),\n\u001b[0;32m   7311\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinewidth\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mnext\u001b[39m(linewidths),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   7314\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mnext\u001b[39m(facecolors),\n\u001b[0;32m   7315\u001b[0m })\n\u001b[1;32m-> 7316\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   7317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lbl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   7318\u001b[0m     p\u001b[38;5;241m.\u001b[39mset_label(lbl)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\doyoung_laplace\\lib\\site-packages\\matplotlib\\artist.py:1233\u001b[0m, in \u001b[0;36mArtist._internal_update\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_internal_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, kwargs):\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;124;03m    Update artist properties without prenormalizing them, but generating\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m \u001b[38;5;124;03m    errors as if calling `set`.\u001b[39;00m\n\u001b[0;32m   1230\u001b[0m \n\u001b[0;32m   1231\u001b[0m \u001b[38;5;124;03m    The lack of prenormalization is to maintain backcompatibility.\u001b[39;00m\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_props\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{cls.__name__}\u001b[39;49;00m\u001b[38;5;124;43m.set() got an unexpected keyword argument \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{prop_name!r}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\doyoung_laplace\\lib\\site-packages\\matplotlib\\artist.py:1206\u001b[0m, in \u001b[0;36mArtist._update_props\u001b[1;34m(self, props, errfmt)\u001b[0m\n\u001b[0;32m   1204\u001b[0m             func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1205\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func):\n\u001b[1;32m-> 1206\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1207\u001b[0m                     errfmt\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), prop_name\u001b[38;5;241m=\u001b[39mk),\n\u001b[0;32m   1208\u001b[0m                     name\u001b[38;5;241m=\u001b[39mk)\n\u001b[0;32m   1209\u001b[0m             ret\u001b[38;5;241m.\u001b[39mappend(func(v))\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret:\n",
      "\u001b[1;31mAttributeError\u001b[0m: Rectangle.set() got an unexpected keyword argument 'num_bins'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "la = Laplace(model, 'classification',\n",
    "            subset_of_weights='all',\n",
    "            hessian_structure='diag',\n",
    "          )\n",
    "la.fit(train_loader)\n",
    "val = la.H.numpy()\n",
    "plt.hist(val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doyoung_laplace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
